{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.arange: array range\n",
    "# a = np.array([1,2,3])\n",
    "a = np.arange(50)\n",
    "# a\n",
    "a.shape # (50, )\n",
    "# a = a.reshape(-1, 1) # old ver.\n",
    "a = np.arange(50)[:, np.newaxis] # new ver.\n",
    "a.shape # (50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.], shape=(50,), dtype=float32)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.]\n",
      "(50,)\n",
      "(50, 1)\n",
      "tf.Tensor(\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [12.]\n",
      " [13.]\n",
      " [14.]\n",
      " [15.]\n",
      " [16.]\n",
      " [17.]\n",
      " [18.]\n",
      " [19.]\n",
      " [20.]\n",
      " [21.]\n",
      " [22.]\n",
      " [23.]\n",
      " [24.]\n",
      " [25.]\n",
      " [26.]\n",
      " [27.]\n",
      " [28.]\n",
      " [29.]\n",
      " [30.]\n",
      " [31.]\n",
      " [32.]\n",
      " [33.]\n",
      " [34.]\n",
      " [35.]\n",
      " [36.]\n",
      " [37.]\n",
      " [38.]\n",
      " [39.]\n",
      " [40.]\n",
      " [41.]\n",
      " [42.]\n",
      " [43.]\n",
      " [44.]\n",
      " [45.]\n",
      " [46.]\n",
      " [47.]\n",
      " [48.]\n",
      " [49.]], shape=(50, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "position=50\n",
    "a = tf.range(position, dtype=tf.float32) # tf.range = np.arange\n",
    "print(a)\n",
    "print(a.numpy()) # tensor -> numpy\n",
    "print(a.shape)   # (50, )\n",
    "\n",
    "a = tf.range(position, dtype=tf.float32)[:, tf.newaxis] # (50, 1)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(1, 128)\n",
      "tf.Tensor(\n",
      "[[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "   14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "   28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "   42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "   56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "   70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "   84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "   98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      "  112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      "  126. 127.]], shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d_model = 128\n",
    "i = tf.range(d_model, dtype=tf.float32)\n",
    "print(i.shape)  # (128, )\n",
    "\n",
    "i = i[tf.newaxis, :]\n",
    "print(i.shape) # (1, 128)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pow(): 거듭제곱(x의 y승), 스칼라일때\n",
    "tf.pow(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 2,  4,  8, 16])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pow(): 한쪽 배열일때\n",
    "i = [1,2,3,4]\n",
    "tf.pow(2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[  256, 65536],\n",
       "       [    9,    27]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pow(): 둘다 배열일때, 원소끼리 거듭제곱\n",
    "x = tf.constant([[2, 2], \n",
    "                 [3, 3]])\n",
    "y = tf.constant([[8, 16], \n",
    "                 [2, 3]])\n",
    "tf.pow(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_model=128\n",
    "i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :] # (1, 128)\n",
    "i // 2 # 001122\n",
    "2 * (i // 2) # 002244\n",
    "tf.pow(10000, (2 * (i // 2))) # inf\n",
    "(2 * (i // 2)) / tf.cast(d_model, tf.float32) # 2/128 ~ 126/128: 최대 숫자가 1 미만\n",
    "y = tf.pow(10000, (2 * (i // 2))/ tf.cast(d_model, tf.float32))\n",
    "# i\n",
    "# y\n",
    "# plt.plot(i, y, \"ro\")\n",
    "plt.plot(i[0], y[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd4ElEQVR4nO3de3zcdZ3v8ddnZpJMc29z6SVNSEsvUO5SKIiLVUBbcEXOeh6WxcsiiuyKK+56VlzWvTx0L+fh6sFVBDnIwTsPL6jVrYAgFxFb2nJrSymEXtP0kjZt2jRtbvM5f8ykTNO0mbaT/GZ+834+Hnkkv9/8MnkHmne++c739/uZuyMiIvkvEnQAERHJDhW6iEhIqNBFREJChS4iEhIqdBGRkIgF9YVra2u9ubk5qC8vIpKXVq5cucvd64Z7LLBCb25uZsWKFUF9eRGRvGRmm471mKZcRERCQoUuIhISKnQRkZBQoYuIhIQKXUQkJEYsdDO738x2mtnqYzxuZvZfZtZiZi+b2VuyH1NEREaSyQj9AWDBcR5fCMxMvd0M3H3qsURE5ESNuA7d3Z82s+bjHHIt8F1PXod3qZlVm9lkd9+WrZDp1m3fz3+/3JbcMOO6CxqYVls2Gl9KRCSvZOPEogZgS9p2a2rfUYVuZjeTHMXT1NR0Ul+sZWcXX3+iBQB36DjQw5fed85JPZeISJhko9BtmH3D3jXD3e8F7gWYO3fuSd1Z45pzJ3PNudcA8K7/8xQ79/WczNOIiIRONla5tAKNadtTgbYsPO+IastL2NWlQhcRgewU+mLgw6nVLpcAnaM1fz5UstB7x+JLiYjkvBGnXMzsR8B8oNbMWoF/AooA3P0eYAlwNdACdAM3jlbYoTRCFxF5UyarXK4f4XEHPpm1RCegtqKY7t4Bunv7KS0O7MKRIiI5Ia/PFK0rLwFg135Nu4iI5HWh11YkC72961DASUREgpfXhT44Qm/XCF1EJL8LvXZwykUvjIqI5Heh15QXAyp0ERHI80IvikaoLi1SoYuIkOeFDsl5dK1yEREJQaHXlpfQrhG6iEgICr1CZ4uKiEAYCr28mF37VegiIiEo9BIO9A5wsHcg6CgiIoHK+0Kv01p0EREgDIV++PR/FbqIFLa8L/Taw6f/q9BFpLDlf6FX6GxREREIQaHXlOkSuiIiEIJCL45FqBqn0/9FRPK+0CG1Fl2FLiIFLhSFXqezRUVEwlHoteUltO/vIZFwEgkPOo6ISCBCUej1FXE27u5m+t8vYfYXfsOy9buDjiQiMuZiQQfIhhsva2Z8aRE9/Qm+8UQLq7Z2Mm96TdCxRETGVCgKvXFCKZ+6Yibuzv/9/Xp27NNNo0Wk8IRiymWQmTGpKs72fXqBVEQKT6gKHWBiRVwjdBEpSOEr9CoVuogUptAV+qTKErZ3HsJdyxdFpLCErtAnVsbp6U+w72B/0FFERMZUKAsdYLumXUSkwISu0CdVqdBFpDCFr9BTI/QdnSp0ESksGRW6mS0ws3Vm1mJmtw/zeJWZ/crMXjKzNWZ2Y/ajZmbwlnRa6SIihWbEQjezKHAXsBCYA1xvZnOGHPZJ4BV3Pw+YD3zFzIqznDUj8aIo40uLNOUiIgUnkxH6xUCLu693917gQeDaIcc4UGFmBpQDHUBgy0wmVmotuogUnkwKvQHYkrbdmtqX7hvAmUAbsAr4tLsnhj6Rmd1sZivMbEV7e/tJRh7ZpKo4O3T6v4gUmEwK3YbZN/SsnXcDLwJTgPOBb5hZ5VGf5H6vu89197l1dXUnGDVzEyvimnIRkYKTSaG3Ao1p21NJjsTT3Qg85EktwAbgjOxEPHETq+Ls6uqhb+CoPxJEREIrk0JfDsw0s2mpFzoXAYuHHLMZuALAzCYCs4H12Qx6IiZVxnGH9v2adhGRwjFiobt7P3Ar8AiwFvixu68xs1vM7JbUYV8E3mpmq4DHgc+5+67RCj2SiZVauigihSejG1y4+xJgyZB996R93Aa8K7vRTt7g6f8qdBEpJKE7UxTSTv/X2aIiUkBCWegTSospiho7NIcuIgUklIUeiRj1FXFa9xyk82Afh/oGgo4kIjLqQnGT6OFMqY7zq5fa+NVLbYwrivL0373j8HVeRETCKLSF/s/vPYul6zvY0tHNA89u5PWd+1XoIhJqoS30s6ZUcdaUKjbuOsADz25k656DQUcSERlVoZxDTze5OrniZeteFbqIhFvoC70kFqW+ooQ2FbqIhFzoCx2gYfw4jdBFJPQKo9Crx2kOXURCr2AKvW3vIRKJoVf9FREJj8Io9PHj6B1IsKtLZ46KSHgVRqFXjwOgVfPoIhJihVHo45OFrnl0EQmzwij01AhdSxdFJMwKotAr4kVUxmNauigioVYQhQ7QML5UUy4iEmqFU+jVOrlIRMKtYAp96nidXCQi4VYwhd5QPY79Pf10HuwLOoqIyKgonELX0kURCbnCKfTU0kXNo4tIWBVOoadG6M9v3sPqrZ206wbSIhIyob1j0VA1ZcVUxGPc/eQb3P3kG9RVlPDc31+BmQUdTUQkKwqm0M2Mn9xyKZt3d/Pka+38cNlmOg70UlOu+4yKSDgUzJQLwBmTKnnXWZO48sx6ADZ1dAecSEQkewqq0Ac1TSgDYNPuAwEnERHJnoIs9MYJ4zCDjbs0QheR8CjIQi+JRZlSNY7NmnIRkRApyEIHOK2mlI2achGREMmo0M1sgZmtM7MWM7v9GMfMN7MXzWyNmT2V3ZjZd1pNGZt2a4QuIuEx4rJFM4sCdwFXAa3AcjNb7O6vpB1TDXwTWODum82sfpTyZs1pNaV0HOhl36E+KuNFQccRETllmYzQLwZa3H29u/cCDwLXDjnmz4GH3H0zgLvvzG7M7GuuKQVgs0bpIhISmRR6A7Albbs1tS/dLGC8mT1pZivN7MPDPZGZ3WxmK8xsRXt7+8klzpLTapJLFzWPLiJhkUmhD3duvA/ZjgEXAtcA7wa+YGazjvok93vdfa67z62rqzvhsNnUNCE5Qtc8uoiERSan/rcCjWnbU4G2YY7Z5e4HgANm9jRwHvBaVlKOgrKSGHUVJTq5SERCI5MR+nJgpplNM7NiYBGweMgxvwT+xMxiZlYKzAPWZjdq9jXXlGqELiKhMeII3d37zexW4BEgCtzv7mvM7JbU4/e4+1ozexh4GUgA97n76tEMng1NE8r4Q8uuoGOIiGRFRldbdPclwJIh++4Zsv1l4MvZizb6mmtK+dnzhzjUN0C8KBp0HBGRU1KwZ4oCNA0uXdQlAEQkBArmeujDmVabXLq44M6nMTP+/OImvvi+swNOJSJycgq60M+eUsU/XHMme7v7eGztDp56Ldi18SIip6KgCz0SMT72J9MBiEWNrz3+uubTRSRvFfQceroZ9eW4w/p2rUsXkfykQk+ZUV8OwOs79wecRETk5KjQU6bVlhExeGNnV9BRREROigo9pSQWpWlCKS3tKnQRyU8q9DQz6ito0QhdRPKUCj3NjPpyNuw6QP9AIugoIiInTIWeZkZ9OX0DziadOSoieUiFnmZwpYumXUQkH6nQ06jQRSSfqdDTlJfEmFwV19JFEclLKvQhZtSXa+miiOQlFfoQp9eV07Kzi11dPew50Iv70NuniojkpoK+ONdwZk+qoLt3gLlfegyAO64+k49fPj3gVCIiI1OhD3Ht+VMwoHcgwbeeWs/S9btV6CKSF1ToQ5QWx1h0cRMAKzftYfmGjoATiYhkRnPox3Hm5EraOg+xt7s36CgiIiNSoR/HnMmVALyybV/ASURERqZCP44zBwu9TYUuIrlPhX4cdRUl1FWUsHabbnohIrlPhT6COZMrNeUiInlBhT6CMydX0rJzP739uqSuiOQ2FfoI5kyppG/AdcEuEcl5KvQRDK50WatpFxHJcSr0EUyrLSNeFNE8uojkPBX6CKIRY/akSp7fvIe12/axvr1LF+wSkZykQs/AuQ1VvLB5Lwu/9nve+ZWneGLdzqAjiYgcRddyycDfvmsWl82oxd359IMvsnR9B+88Y2LQsUREjpDRCN3MFpjZOjNrMbPbj3PcRWY2YGbvz17E4FWXFrPg7EksPGcyc6ZU8uKWvUFHEhE5yoiFbmZR4C5gITAHuN7M5hzjuP8NPJLtkLnk/MZqVrV20j+gdekiklsyGaFfDLS4+3p37wUeBK4d5rhPAT8DQj3BfEFTNQf7Bnhth9ali0huyaTQG4AtadutqX2HmVkDcB1wz/GeyMxuNrMVZraivb39RLPmhPMbqwE07SIiOSeTQrdh9g1dt3cn8Dl3HzjeE7n7ve4+193n1tXVZRgxtzRNKGV8aREvbtkTdBQRkSNkssqlFWhM254KtA05Zi7woJkB1AJXm1m/u/8iGyFziZlxXmO1RugiknMyGaEvB2aa2TQzKwYWAYvTD3D3ae7e7O7NwE+BvwpjmQ86v7Ga13d2sf9QX9BRREQOG7HQ3b0fuJXk6pW1wI/dfY2Z3WJmt4x2wFx0fmM17rCqtTPoKCIih2V0YpG7LwGWDNk37Aug7v4Xpx4rtw2+MPrClr1cenoNkJyKEREJkk79PwnVpcVMry3jy4+sY9rnl3Dhlx5jzwHdSFpEgqVCP0n//j/O4bYrZ/LhS0+j40AvS9fvDjqSiBQ4XcvlJM2bXsO86TX0DST4yYpWlq7fzcJzJgcdS0QKmEbop6goGmFu83iWbegIOoqIFDgVehZcMr2GV7fv1zy6iARKhZ4F86ZNANAoXUQCpULPgnOnVhMvirBsg14YFZHgqNCzoDgW4cLTxrN0vUboIhIcFXqWzJtWw6vb97G3W/PoIhIMFXqWzJs2AXf49jMbWLJqG2u37Qs6kogUGK1Dz5Lzm6qpjMf4+u9aAKiMx1j5hasoiup3poiMDRV6lpTEovzus/PZ3dXLcxt284VfrmHlpj1cMr0m6GgiUiA0fMyi2vISZk+q4H0XNBCLGE+uy8+7MolIflKhj4KKeBEXNU/gyXWhvr2qiOQYFfoomT+7jle372db58Ggo4hIgVChj5L5s+sBeErTLiIyRlToo2TWxHImV8U1jy4iY0aFPkrMjPmz63mmZRe9/Ymg44hIAVChj6L5s+vo6unnvH95lLP+8WH+bcnaoCOJSIip0EfRO2bXc9uVM7lhXhMzJlbww2WbOdQ3EHQsEQkpFfooKo5FuO3KWfzDe+bwmStn0tXTzzOv7wo6loiElAp9jFw2o5aqcUUsWbUt6CgiElIq9DFSFI3wrjkT+e3aHfT0a9pFRLJPhT6Grj5nMvsP9fOHFk27iEj2qdDH0GUzaqmIx1iyanvQUUQkhHS1xTFUHItw1ZyJLFm1jb3dfUQM/nL+6VzQND7oaCISAir0MfaRS5t5Y2cXbXsPsmn3AXr6E3znoxcHHUtEQkCFPsbOa6zml7e+DYCvPrqOrz/RwrbOg0yuGhdwMhHJd5pDD9D7L2zEHR56fmvQUUQkBFToAWqqKeWS6RP48YotuHvQcUQkz2VU6Ga2wMzWmVmLmd0+zOM3mNnLqbdnzey87EcNp/95YSObdnfz3IaOoKOISJ4bsdDNLArcBSwE5gDXm9mcIYdtAN7u7ucCXwTuzXbQsFp4ziTKS2L81+9e5/tLN/GTFVt0dUYROSmZvCh6MdDi7usBzOxB4FrglcED3P3ZtOOXAlOzGTLMSotjvP/CqTzw7Eb+0LIbgK6efm68bFrAyUQk32Qy5dIAbEnbbk3tO5abgN8M94CZ3WxmK8xsRXu7bvww6J/+dA7P3XEFz91xBW9pquaBZzcykNCcuoicmEwK3YbZN2zbmNk7SBb654Z73N3vdfe57j63rq4u85QhZ2bUV8Spr4hz09ums2l3N4+v3RF0LBHJM5kUeivQmLY9FWgbepCZnQvcB1zr7ruzE6/wvPusiTRUj+Pbz2wIOoqI5JlMCn05MNPMpplZMbAIWJx+gJk1AQ8BH3L317Ifs3DEohE+8tbTWLahg9VbO4OOIyJ5ZMQXRd2938xuBR4BosD97r7GzG5JPX4P8I9ADfBNMwPod/e5oxc73D5wURN3PvY677vrD0QjRm15Cb/61NuYUFYcdDQRyWEW1Aktc+fO9RUrVgTytfPBY6/sYPmmDvoHnPv/sIGbL5/O5xeeGXQsEQmYma081oBZ13LJUVfOmciVcyYCsLurh+8+u4mPvW06dRUlAScTkVylU//zwF9fMZOe/gG+9dQbQUcRkRymEXoemF5XznUXTOV7Szdx2YxaSooizKyv0GhdRI6gQs8Tn75iJotf2sqNDywHYEJZMY//zdsZrxdKRSRFUy55oqmmlIdvu5wHb76Eb97wFjoP9vGV364LOpaI5BCN0PPI6XXlnF5XDsBzGzr47h83cv3FTZw1pSrgZCKSCzRCz1OfuXIW1aXF/PPiNby6fR+vbt9H34Cu0ihSyFToeaqqtIj/9e7ZLN+4hwV3/p4Fd/6eD963TBf1EilgmnLJY4suaqS5poy93b2s27GfOx97nfuf2cDHL58edDQRCYAKPY+ZGZeeXgPAgrMn8UrbPr786Drmz65j5sSKgNOJyFjTlEtImBn/et05lBVH+fh3V3Dbgy/w2Z+8xNpt+4KOJiJjRIUeInUVJXz1A+cTi0Z4YcteHl69nY8+sJxdXT1BRxORMaApl5B5x+x63jG7HoDVWzv5s7uf5VM/fIHv3XQxsah+f4uEmQo9xM5uqOJfrzuHz/7kJW76zgqaJpRSVhLjE5dP1xmmIiGkQg+59184lQ27uvjRc1tYtbWTzoN9LNuwmx98bB6lxfrfLxImuh56gXl49Tb+6gfPM392Pd/60IUUaRpGJK8c73roKvQC9INlm7jj56spL4kRjRiTKuPcdcNbmFFfHnQ0ERmBbnAhR7hh3mmUFcd4ccteAH798jY+8K0/8r2b5jFnSmWw4UTkpGmELqxv7+KG+5bR3TvAO89IrpA5a0olH71sGpGIBZxORNIdb4SuCVRhel05P/7EpcyaWM7KTXt4bkMHX/rvtXzi+ys50NMfdDwRyZBG6HIUd+eBZzfyxV+/QnNtGWenLs87f3Yd113QgJlG7SJB0Ry6nBAz48bLpnF6XTn//ptXWbW1k4O9Ayx+qY3H1+7k3647h6rSoqBjisgQKnQ5pstn1XH5rDoABhLOvU+v5yuPruOxtTuIF0WJRozrLmjgb66aRVmJ/imJBE0/hZKRaMT4y/mnc9mMGn7xQhsJd9q7evj2Mxv4zaptfOjSZopjEcYVRbnm3MlUjdMIXmSsaQ5dTsnKTXu44+ereHX7/sP7qkuL+OT8GbzzzHoMqBpXRE15SXAhRUJEJxbJqHJ39h1KrobZtPsA//noazz9WvvhxyMG15w7hU9cPv3wyUvF0YiWRIqcBBW6jLmVm/bQuqcbgDVt+/jhss10pS2BrK8oYdFFjfzZhVOpLk1eKKwyHtMKGpERqNAlcJ0H+/jVS23sO9SHO6zY2MGTr7WT/s+voXocf3reFN4+q47iWISIwRmTKhlXHA0uuEiOUaFLTtrS0c0T63bSN+AMJBL88Y3dPP36riNudF0Si/C2GbWc1VCFAcWxCBeeNp4LmqopianopfCo0CVv7O7qYU3bPhw41DfAH9/YzWNrd9C65+ARx8WLItSmXmgtL4lxfmM1FzRVUxFPrq4ZX1rMWQ2VVMa12kbCRYUuobHvUB/L1nfwxzd2s/dgLwAdB3p5ftOewy/MpptSFac4lrzCxcTKOLMmVtA4YRwRM8yMKVVxmmvLqCkrBoOiSITq0iLN5UvOOuUzRc1sAfA1IArc5+7/MeRxSz1+NdAN/IW7P39KqUWGURkv4qo5E7lqzsQj9icSzuaObnr6EzjOjn09rN7ayRs7uxhwJ+HQtvcgv3hhK/tHuD5NvCjC1PGllKXm7otjESZVjWNSZcnh68eXFkepr4gzvqyYwUvKl5cUMaGsmMp4DAwMoyIeI16kqSEZGyMWuplFgbuAq4BWYLmZLXb3V9IOWwjMTL3NA+5OvRcZE5GI0Vxbdnj7jEnw9tRZrunc/fBqm4GE07rnIBt2HaDzYB8Avf0J2vYepHXPQQ71DwDQ3TvAy617+e2+QwwkHHfoT2T+l228KHnCFUDEkiVfES+iKJr8KyAWiVAej1FanDz7FqAoGqGsOEq8OEosYkTNiEYiRCPJ7zUWMSJmFMcixCIRiqJGUTRCUTRCLGqHl4VGDKKpv0aiqe3Bj2OR5PvDb/bmx8m/YEi+kfy8N/cl30cs9Xy8eWxyn2Fw+FgZO5mM0C8GWtx9PYCZPQhcC6QX+rXAdz05f7PUzKrNbLK7b8t6YpFTYGaH59kBqkuLObuh6oSf51DfAO37e9jT3Ys7OLD/UB8dB3rZn5r6GVyfv7e7l57+BJD8RdB1qJ99h/oOv/jbN5CgfX8PB3r6SfjgvuQvnoO9Awy4H/FCcb5J/lJI+4WQ/PPliF8Gg78ESP/FccRzJLcs7TnTHj1q33DH2ZDjhnv+oblP5jmGiXbUcYsuauRjfzL9qK95qjIp9AZgS9p2K0ePvoc7pgE4otDN7GbgZoCmpqYTzSqSM+JFURonlNI4oXTMvmYi4fQnnESq4PsTTv9Agr4Bp28gQd9Agv6E09uf/DjhkHAnkUhOOXlq6mkgtW/wOQYSnvqlkaB/IPn87iQ/hzc/1wefb8i2w+HPcXcGEsnPG/xFN3jsm8+V/BhP+7y05yD18aDBD5NfiSOWuvqQY9L3HnHcCT7H4HEMe5wPfSjt+dP3HX3c4EbtKJ05nUmhD/c309DhQibH4O73AvdC8kXRDL62iKREIkaxzq6V48jkBhetQGPa9lSg7SSOERGRUZRJoS8HZprZNDMrBhYBi4ccsxj4sCVdAnRq/lxEZGyNOOXi7v1mdivwCMlli/e7+xozuyX1+D3AEpJLFltILlu8cfQii4jIcDJah+7uS0iWdvq+e9I+duCT2Y0mIiInQjeJFhEJCRW6iEhIqNBFREJChS4iEhKBXW3RzNqBTSf56bXArizGGWvKHyzlD5byn5rT3P3oCxURYKGfCjNbcazLR+YD5Q+W8gdL+UePplxEREJChS4iEhL5Wuj3Bh3gFCl/sJQ/WMo/SvJyDl1ERI6WryN0EREZQoUuIhISeVfoZrbAzNaZWYuZ3R50npGYWaOZPWFma81sjZl9OrV/gpn91sxeT70fH3TWYzGzqJm9YGa/Tm3nTXaA1C0Rf2pmr6b+P1yaL9+DmX0m9e9mtZn9yMziuZ7dzO43s51mtjpt3zEzm9nnUz/P68zs3cGkftMx8n859e/nZTP7uZlVpz2WM/nzqtDTbli9EJgDXG9mc4JNNaJ+4G/d/UzgEuCTqcy3A4+7+0zg8dR2rvo0sDZtO5+yA3wNeNjdzwDOI/m95Pz3YGYNwF8Dc939bJKXr15E7md/AFgwZN+wmVM/C4uAs1Kf883Uz3mQHuDo/L8Fznb3c4HXgM9D7uXPq0In7YbV7t4LDN6wOme5+zZ3fz718X6SZdJAMvd3Uod9B3hfIAFHYGZTgWuA+9J250V2ADOrBC4Hvg3g7r3uvpf8+R5iwDgziwGlJO8EltPZ3f1poGPI7mNlvhZ40N173H0DyXsqXDwWOY9luPzu/qi796c2l5K8KxvkWP58K/Rj3Yw6L5hZM3ABsAyYOHhXp9T7+gCjHc+dwN8BibR9+ZIdYDrQDvy/1LTRfWZWRh58D+6+FfhPYDPJG653uvuj5EH2YRwrcz7+TH8U+E3q45zKn2+FntHNqHORmZUDPwNuc/d9QefJhJm9B9jp7iuDznIKYsBbgLvd/QLgALk3RTGs1DzztcA0YApQZmYfDDZV1uXVz7SZ3UFyGvUHg7uGOSyw/PlW6Hl5M2ozKyJZ5j9w94dSu3eY2eTU45OBnUHlO47LgPea2UaS01vvNLPvkx/ZB7UCre6+LLX9U5IFnw/fw5XABndvd/c+4CHgreRH9qGOlTlvfqbN7CPAe4Ab/M0TeHIqf74VeiY3rM4pZmYk52/XuvtX0x5aDHwk9fFHgF+OdbaRuPvn3X2quzeT/G/9O3f/IHmQfZC7bwe2mNns1K4rgFfIj+9hM3CJmZWm/h1dQfI1mHzIPtSxMi8GFplZiZlNA2YCzwWQ77jMbAHwOeC97t6d9lBu5Xf3vHojeTPq14A3gDuCzpNB3reR/BPsZeDF1NvVQA3JV/tfT72fEHTWEb6P+cCvUx/nW/bzgRWp/we/AMbny/cA/AvwKrAa+B5QkuvZgR+RnPPvIzmCvel4mYE7Uj/P64CFOZq/heRc+eDP8D25mF+n/ouIhES+TbmIiMgxqNBFREJChS4iEhIqdBGRkFChi4iEhApdRCQkVOgiIiHx/wGFCs2W50ro7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)) \n",
    "# print(angles.shape)\n",
    "# print(angles)\n",
    "\n",
    "x = i[0].numpy()\n",
    "# print(x)\n",
    "y = angles[0].numpy()\n",
    "# print(y)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "# 로그 스케일: 뒤로 갈수록 간격이 좁아진다\n",
    "# d_model 수가 (128이 아닌 256로) 바뀌어도 로그 스케일로 0~1 범위로 나온다.\n",
    "# 두 개씩 같은 값, 쌍으로 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5)\n",
    "# print(a.shape) # (4,)\n",
    "a = np.arange(1,5).reshape(4,1)\n",
    "# print(a.shape) # (4,1)\n",
    "\n",
    "b = 3\n",
    "c = a*b  # broadcasting (4,1)*() => (4,1)(4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(4,1)\n",
    "b = np.array([3]) # (1, )\n",
    "c = a*b  # axis=0(row)으로 리피트: (4,1)*(1,) => (4,1)*(4,1) => (4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27744/2550319264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               [3,3]])\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m  \u001b[1;31m# (4,3)*(4,2) => Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,2) "
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(4,3)\n",
    "b = np.array([[3,3],\n",
    "              [3,3],\n",
    "              [3,3],\n",
    "              [3,3]])\n",
    "c = a*b  # (4,3)*(4,2) => Error\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[ 3  6  9]\n",
      " [12 15 18]\n",
      " [21 24 27]\n",
      " [30 33 36]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(4,3)\n",
    "b = np.array([[3],\n",
    "              [3],\n",
    "              [3],\n",
    "              [3]])\n",
    "c = a*b  # 1열일때는 열 복제 가능: (4,3)*(4,1) => (4,3)*(4,3)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4).reshape(1,3)\n",
    "print(a)\n",
    "b = np.array([[0],\n",
    "              [1],\n",
    "              [2],\n",
    "              [3]])\n",
    "print(b)\n",
    "c = a*b  # 1열일때는 열 복제 가능: (1,3)*(4,1) => (4,3)(4,3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.89399666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 라디안\n",
    "print(tf.math.sin(90.*np.pi/180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.84147096, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.__init__()\", position, d_model)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "#         print(\"PositionalEncoding.get_angles()\")\n",
    "#         print(position.shape)  # (50,1)\n",
    "#         print(i.shape)         # (1,128)\n",
    "#         print(d_model)         # 128\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "#         print(angles.shape)    # (1,128)\n",
    "#         print(angles)\n",
    "        return position * angles    # 1열일때 열 복제 가능: (50,1)*(1,128) => (50,128)*(50,128) => (50,128)\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.positional_encoding()\", position, d_model)\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  # (50,1)\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],          # (1,128)\n",
    "            d_model=d_model)\n",
    "\n",
    "#         print(angle_rads[:10,:10])\n",
    "        print(angle_rads.shape)  # (50,128)\n",
    "        \n",
    "#         print(angle_rads[:10, 0:11:2])\n",
    "#         print(angle_rads[:, 0::2].shape)\n",
    "        \n",
    "        # 배열의 짝수 인덱스(2i, 0,2,4,...)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        print(sines[:10,:10])\n",
    "        print(sines.shape) # (50, 64)\n",
    "        \n",
    "        # 배열의 홀수 인덱스(2i+1, 1,3,5,...)에는 코사인 함수 적용\n",
    "        # 같은 각도이지만, 다른 값\n",
    "        # ex) 0.84147096 != 0.5403023\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        print(cosines[:10,:10])\n",
    "        print(cosines.shape) # (50, 64)\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        print(pos_encoding.shape) # (50, 128)\n",
    "        print(pos_encoding[:10,:10])\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)  # (1, 50,128)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):  # (1,40,128): 더 적은 input이 들어와도 OK\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :] # (1,40,128)+(1,40,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "(50, 64)\n",
      "tf.Tensor(\n",
      "[[ 1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.        ]\n",
      " [ 0.5403023   0.6479058   0.731761    0.7964579   0.84600914  0.8837559\n",
      "   0.91239583  0.9340616   0.95041525  0.962739  ]\n",
      " [-0.4161468  -0.16043602  0.07094827  0.2686903   0.43146282  0.56204915\n",
      "   0.66493237  0.74494207  0.8065784   0.8537328 ]\n",
      " [-0.9899925  -0.8558007  -0.6279267  -0.36845687 -0.11596616  0.1096727\n",
      "   0.3009673   0.45758203  0.58275366  0.6811047 ]\n",
      " [-0.6536436  -0.94852054 -0.9899327  -0.855611   -0.6276797  -0.36820143\n",
      "  -0.11572982  0.10987744  0.30113748  0.45771942]\n",
      " [ 0.28366217 -0.3733035  -0.82086164 -0.99445945 -0.94607925 -0.760473\n",
      "  -0.5121501  -0.2523174  -0.01034234  0.2002239 ]\n",
      " [ 0.96017027  0.46478963 -0.21141617 -0.728479   -0.9731037  -0.9759438\n",
      "  -0.81883734 -0.5812374  -0.32079637 -0.07219268]\n",
      " [ 0.75390226  0.9755833   0.5114493  -0.16594627 -0.7004298  -0.9645192\n",
      "  -0.98205763 -0.83350575 -0.5994375  -0.33922932]\n",
      " [-0.14550003  0.79938257  0.95993346  0.4641406  -0.21203645 -0.72885543\n",
      "  -0.9732132  -0.9758539  -0.8186324  -0.5809859 ]\n",
      " [-0.91113025  0.06026585  0.89343446  0.90528315  0.34166023 -0.32374159\n",
      "  -0.7938539  -0.9895096  -0.9566442  -0.7794462 ]], shape=(10, 10), dtype=float32)\n",
      "(50, 64)\n",
      "(50, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "(1, 50, 128)\n",
      "tf.Tensor(\n",
      "[[[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844\n",
      "    0.46794808  0.40930894  0.35711196  0.3109836   0.27043223]\n",
      "  [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307\n",
      "    0.82710385  0.74690354  0.66712916  0.5911271   0.52071136]\n",
      "  [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532\n",
      "    0.9939678   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      "  [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717\n",
      "    0.92974603  0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      "  [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527\n",
      "    0.64936954  0.85889596  0.9676445   0.99994653  0.97975016]\n",
      "  [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753\n",
      "    0.21802224  0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      "  [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213\n",
      "   -0.2640126   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      "  [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618\n",
      "   -0.6846676  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      "  [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235\n",
      "   -0.94614553 -0.6081086  -0.14446725  0.29125923  0.6264692 ]]], shape=(1, 10, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "print(sample_pos_encoding.pos_encoding.shape) # (1,50,128)\n",
    "                                              # (N,T,D)\n",
    "                                              # tf.shape(inputs)[1]\n",
    "print(sample_pos_encoding.pos_encoding[:, :10, :10])\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128)) # 0~64: sin, 65~128: cos 결과, 모든 행과 열의 값이 모두 다르다.\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n",
      "tf.Tensor(\n",
      "[[[0.0000000e+00 1.0000000e+00 2.0000000e+00 ... 1.2600000e+02\n",
      "   1.2700000e+02 1.2800000e+02]\n",
      "  [1.2884148e+02 1.2976172e+02 1.3068156e+02 ... 2.5400000e+02\n",
      "   2.5500000e+02 2.5600000e+02]\n",
      "  [2.5690930e+02 2.5798706e+02 2.5899747e+02 ... 3.8200000e+02\n",
      "   3.8300000e+02 3.8400000e+02]\n",
      "  ...\n",
      "  [6.0161235e+03 6.0171401e+03 6.0173652e+03 ... 6.1420000e+03\n",
      "   6.1430000e+03 6.1440000e+03]\n",
      "  [6.1432319e+03 6.1443364e+03 6.1450088e+03 ... 6.2700000e+03\n",
      "   6.2710000e+03 6.2720000e+03]\n",
      "  [6.2710464e+03 6.2720000e+03 6.2731841e+03 ... 6.3980000e+03\n",
      "   6.3990000e+03 6.4000000e+03]]], shape=(1, 50, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "N=1\n",
    "T=50\n",
    "D=128\n",
    "a = np.arange(N*T*D).reshape(N,T,D)\n",
    "inputs = tf.constant(a, dtype=tf.float32)\n",
    "result = sample_pos_encoding(inputs)\n",
    "print(result.shape) # (1, 50, 128)\n",
    "print(result) # +Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "(2, 2, 3)\n",
      "[[[ 1.  1.  1.]\n",
      "  [ 5.  5.  5.]]\n",
      "\n",
      " [[ 9.  9.  9.]\n",
      "  [13. 13. 13.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(8).reshape(2,2,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(x,w)    # (2,2,2)(2,3)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12).reshape(2,3,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(w,x)    # (2,3)(2,2,2)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "(2, 2)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[ 3.  3.]\n",
      " [12. 12.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열의 행렬 곱 (s445)\n",
    "query = tf.constant(np.arange(6).reshape(2,3),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,3)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)\n",
    "\n",
    "# 동시에 여러개 있을때는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]]\n",
      "\n",
      " [[ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)\n",
      "(2, 2, 2)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[ 3.  3.]\n",
      "  [12. 12.]]\n",
      "\n",
      " [[21. 21.]\n",
      "  [30. 30.]]], shape=(2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2문장이 있을때 (s446)\n",
    "query = tf.constant(np.arange(12).reshape(2,2,3),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,2,3)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True) # (2,2,3)*(2,3,2)=(2,2,2)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.  1.  2.  3.]\n",
      "   [ 4.  5.  6.  7.]\n",
      "   [ 8.  9. 10. 11.]]\n",
      "\n",
      "  [[12. 13. 14. 15.]\n",
      "   [16. 17. 18. 19.]\n",
      "   [20. 21. 22. 23.]]]], shape=(1, 2, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]], shape=(1, 2, 3, 4), dtype=float32)\n",
      "(1, 2, 3, 3)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[[ 6.  6.  6.]\n",
      "   [22. 22. 22.]\n",
      "   [38. 38. 38.]]\n",
      "\n",
      "  [[54. 54. 54.]\n",
      "   [70. 70. 70.]\n",
      "   [86. 86. 86.]]]], shape=(1, 2, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 4차원\n",
    "query = tf.constant(np.arange(24).reshape(1,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((1,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.  1.  2.  3.]\n",
      "   [ 4.  5.  6.  7.]\n",
      "   [ 8.  9. 10. 11.]]\n",
      "\n",
      "  [[12. 13. 14. 15.]\n",
      "   [16. 17. 18. 19.]\n",
      "   [20. 21. 22. 23.]]]\n",
      "\n",
      "\n",
      " [[[24. 25. 26. 27.]\n",
      "   [28. 29. 30. 31.]\n",
      "   [32. 33. 34. 35.]]\n",
      "\n",
      "  [[36. 37. 38. 39.]\n",
      "   [40. 41. 42. 43.]\n",
      "   [44. 45. 46. 47.]]]], shape=(2, 2, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]], shape=(2, 2, 3, 4), dtype=float32)\n",
      "(2, 2, 3, 3)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[[  6.   6.   6.]\n",
      "   [ 22.  22.  22.]\n",
      "   [ 38.  38.  38.]]\n",
      "\n",
      "  [[ 54.  54.  54.]\n",
      "   [ 70.  70.  70.]\n",
      "   [ 86.  86.  86.]]]\n",
      "\n",
      "\n",
      " [[[102. 102. 102.]\n",
      "   [118. 118. 118.]\n",
      "   [134. 134. 134.]]\n",
      "\n",
      "  [[150. 150. 150.]\n",
      "   [166. 166. 166.]\n",
      "   [182. 182. 182.]]]], shape=(2, 2, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 4차원 - 2개 동시에 (고차원 텐서 이용 시 나눠서 수행하는 것과 같은 효과)\n",
    "query = tf.constant(np.arange(48).reshape(2,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-attention 함수\n",
    "# 실제 데이터는 4차원\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬. transpose_b = b(key)를 전치\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True) # (64,4,40,32)(64,4,32,40) => (64,4,40,40)\n",
    "#     print(\"matmul_qk.shape =\", matmul_qk.shape)         # (1,4,4,4)\n",
    "#     print(\"matmul_qk =\", matmul_qk)                     # [[  0. 100.   0.   0.]]\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32) # k의 열의 크기 (뉴런수)\n",
    "#     print(\"depth=\",depth) # 3.0 -> 32\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "#     print(\"logits=\",logits) # [[ 0.       57.735027  0.        0.      ]]\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)  # 1 * (-1000000000)  # (1,4,4,4) += (1,1,1,4)\n",
    "    print(\"logits=\",logits)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    # 열끼리 가로로 softmax 계산\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "#     print(\"attention_weights=\",attention_weights)  # [[0. 1. 0. 0.]]\n",
    "#     print(\"attention_weights.shape =\",attention_weights.shape)  # (64,4,40,40)(64,4,40,32) -> (64,4,40,32)\n",
    "    \n",
    "#     print(\"value.shape=\", value.shape) # (batch_size=1, num_heads=4, 문장내 단어수=4, depth=32)\n",
    "#     print(\"value=\", value)\n",
    "    \n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value) # (1,4,4,4)(1,4,4,32) => (1,4,4,32)\n",
    "#     print(\"output.shape =\", output.shape)\n",
    "#     print(\"output =\", output) \n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 q, k, v 크기가 같지만 달라도 상관없다\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor([[ 0.       57.735027  0.        0.      ]], shape=(1, 4), dtype=float32)\n",
      "logits= tf.Tensor([[ 0.       57.735027  0.        0.      ]], shape=(1, 4), dtype=float32)\n",
      "attention_weights= tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열) [[0. 1. 0. 0.]], shape=(1, 4)\n",
    "print(temp_out) # 어텐션 값 [[10.  0.]], shape=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights= tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "attention_weights.shape = (3, 4)\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# query 3개인 경우\n",
    "temp_q = tf.constant([[0, 0, 10], \n",
    "                      [0, 10, 0], \n",
    "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(1, 3)\n",
      "[<tf.Variable 'dense_37/kernel:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-0.10356826, -0.37470925,  0.4403298 ,  0.66695535],\n",
      "       [ 0.52871513, -0.6876186 , -0.5321318 , -0.29070854],\n",
      "       [-0.04145581, -0.02151173, -0.67146564,  0.11413956]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_37/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "dense1 = tf.keras.layers.Dense(4)  # weight = (?,4)  , bias = (4,)\n",
    "# dir(dense1)\n",
    "print(dense1.weights)\n",
    "x = tf.constant([[1,2,3]])\n",
    "print(x.shape)\n",
    "out = dense1(x)   # (1,3)(3,4)+(4,)\n",
    "print(dense1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA.__init__\n",
      "BBB.__init__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BBB at 0x1ac6345a640>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AAA():\n",
    "    def __init__(self):\n",
    "        print(\"AAA.__init__\")\n",
    "\n",
    "class BBB(AAA):\n",
    "    def __init__(self):\n",
    "        super(BBB, self).__init__() # 이 부분이 없으면, 부모 생성자 호출안됨\n",
    "        print(\"BBB.__init__\")\n",
    "        \n",
    "# AAA()\n",
    "BBB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "# a = np.arange(10)\n",
    "a = np.reshape(a, (-1,1)) # -1: row 자동 결정\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    # d_model: word_vec의 차원수(512->128로 축소), num_heads (8->4로 축소)\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name) # 부모 생성자 초기화\n",
    "        \n",
    "#         print(\"MultiHeadAttention.__init__()\")\n",
    "        self.num_heads = num_heads     # 4\n",
    "        self.d_model = d_model         # 128\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads  # 32\n",
    "#         print(\"self.depth=\", self.depth)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)  # (특성수, 뉴런수=d_model) = (?,128)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        print(self.query_dense.weights) # empty weight list\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)  # (128,128)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  # batch_size = 동시에 들어가는 문장의 개수 (서로 연관 없는 문장들 동시에 학습)\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "#         print(\"split_heads()\")\n",
    "#         print(inputs.shape) # (N=64,T=40,H=128) => (64, 40, 4, 32)\n",
    "        inputs = tf.reshape(\n",
    "            # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "#         print(inputs.shape) # (64,40,4,32)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3]) # (64,4,40,32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "#         print(\"tf.shape(query) = \",  tf.shape(query))\n",
    "#         print(\"batch_size=\", batch_size)\n",
    "        \n",
    "#         # q,k값이 같다\n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])        \n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)  =>  (64,40,128)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)    # (64,40,128)(128,128) => (64,40,128)\n",
    "        key = self.key_dense(key)          # (64,40,128)(128,128) => (64,40,128)\n",
    "        value = self.value_dense(value)    # (64,40,128)(128,128) => (64,40,128)\n",
    "        \n",
    "#         print(self.query_dense.weights) # weight, bias\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "#         # **input은 같지만, q,k값은 달라진다**\n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])\n",
    "\n",
    "        # 2. 헤드 나누기(Split head) 4차원으로 분리\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape) # (64, 4, 40, 32)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape) # (64, 40, 4, 32)\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model), -1: 다른 변수에 따라 자동 결정(코드의 일반화)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "#         print('concat_attention.shape=',concat_attention.shape)  # (64,40,4,32) => (64,40,128)\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)  # (64,40,128)(128,128) => (64,40,128)\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "logits= tf.Tensor(\n",
      "[[[[-1.38456380e+00  5.36655426e-01  1.17035770e+00 ...  5.50381780e-01\n",
      "     1.89686239e+00 -2.01221156e+00]\n",
      "   [-1.52535033e+00 -1.18862242e-01 -4.07437861e-01 ... -1.80943340e-01\n",
      "     3.11689734e-01  1.87958643e-01]\n",
      "   [-1.43618488e+00  9.35079634e-01 -2.40524626e+00 ... -5.96605092e-02\n",
      "    -1.44967818e+00  2.68884748e-01]\n",
      "   ...\n",
      "   [ 9.27632868e-01 -8.49559188e-01 -2.87375689e-01 ... -4.87829030e-01\n",
      "    -9.42635000e-01  6.10740900e-01]\n",
      "   [-1.08026493e+00  2.89001375e-01 -9.85480919e-02 ...  3.54554206e-01\n",
      "     6.61253870e-01  3.63946855e-01]\n",
      "   [-1.32757211e+00 -4.88605857e-01 -1.21396315e+00 ...  1.30208328e-01\n",
      "     8.88613701e-01  5.80279350e-01]]\n",
      "\n",
      "  [[-1.57611680e+00  8.23904634e-01 -7.69272327e-01 ...  1.00649607e+00\n",
      "    -1.08098483e+00 -1.37076557e-01]\n",
      "   [ 6.94088995e-01  1.80240095e-01  1.19426978e+00 ...  1.00176346e+00\n",
      "     2.04878151e-01 -1.00873649e+00]\n",
      "   [ 2.65507793e+00 -4.49188352e-01  1.98186874e+00 ...  9.84775782e-01\n",
      "     4.96941179e-01  4.74118218e-02]\n",
      "   ...\n",
      "   [-1.33795559e-01  1.26123696e-03  7.48854280e-01 ...  3.32585603e-01\n",
      "    -2.06903934e-01  7.74404764e-01]\n",
      "   [ 1.01141429e+00 -1.41714394e-01 -1.40783191e+00 ... -4.90536094e-01\n",
      "    -1.46093702e+00  3.59244525e-01]\n",
      "   [-1.73351943e-01 -1.27630258e+00 -6.87630296e-01 ... -5.16260862e-01\n",
      "    -4.76555258e-01  9.15360093e-01]]\n",
      "\n",
      "  [[ 8.19095850e-01  7.01116443e-01  8.45582411e-02 ... -1.76128030e+00\n",
      "    -6.36299670e-01 -1.62144732e+00]\n",
      "   [-5.27080297e-01 -5.85553944e-01 -8.56123567e-02 ... -6.53987348e-01\n",
      "    -8.40580463e-01 -1.58056244e-01]\n",
      "   [ 5.18230081e-01  3.75188857e-01 -1.28830478e-01 ...  1.47352505e+00\n",
      "    -2.13710713e+00  1.35504258e+00]\n",
      "   ...\n",
      "   [ 5.94542921e-01  5.73242486e-01  9.84723270e-02 ...  1.50527775e+00\n",
      "    -1.03686476e+00 -2.07973719e+00]\n",
      "   [ 1.07663059e+00  1.31802440e+00 -3.19572985e-01 ...  2.06186131e-01\n",
      "    -4.07939434e-01  1.00905681e+00]\n",
      "   [-1.42756855e+00  2.11652696e-01 -7.31550604e-02 ...  1.03323376e+00\n",
      "     2.06390694e-01  2.37581968e+00]]\n",
      "\n",
      "  [[-7.66844153e-01 -4.43916321e-01  3.73242646e-02 ...  1.42632604e-01\n",
      "    -7.72563040e-01  6.57110572e-01]\n",
      "   [ 1.79009467e-01 -2.28571847e-01  5.84730744e-01 ... -2.97890544e-01\n",
      "    -1.09512126e+00 -8.82395387e-01]\n",
      "   [-1.13462597e-01  8.57650518e-01  4.46675807e-01 ... -5.24957120e-01\n",
      "    -7.34329700e-01  5.32403111e-01]\n",
      "   ...\n",
      "   [ 2.80993730e-02 -4.16599303e-01 -2.38275439e-01 ... -8.13041449e-01\n",
      "     1.66673875e+00  1.00372326e+00]\n",
      "   [-8.33753288e-01 -9.82754171e-01 -8.58644187e-01 ... -1.09906765e-02\n",
      "    -1.01881281e-01  1.03611636e+00]\n",
      "   [ 5.89462779e-02  1.11603630e+00  3.60806823e-01 ... -3.24723303e-01\n",
      "     9.90040779e-01 -1.15402603e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.33936316e-01  4.97787416e-01 -3.10962647e-01 ... -6.11139953e-01\n",
      "     1.09357154e+00  9.32807252e-02]\n",
      "   [ 5.84106386e-01 -1.69569111e+00  5.48095167e-01 ... -2.30741695e-01\n",
      "    -2.39280209e-01  6.26081765e-01]\n",
      "   [ 2.24474168e+00 -4.86812472e-01  4.10035312e-01 ...  7.91652858e-01\n",
      "     4.50270623e-01 -9.71468508e-01]\n",
      "   ...\n",
      "   [ 2.64566272e-01 -6.80764556e-01  4.60770905e-01 ... -1.40172154e-01\n",
      "    -9.30395007e-01 -3.06837142e-01]\n",
      "   [-7.81320512e-01 -1.09195733e+00 -1.40097475e+00 ... -1.29308689e+00\n",
      "    -1.01010931e+00  4.51742500e-01]\n",
      "   [ 9.15731907e-01 -8.01194847e-01  1.26436412e+00 ... -1.44503891e-01\n",
      "     7.29160532e-02 -2.12486923e-01]]\n",
      "\n",
      "  [[ 7.20614672e-01 -3.19188982e-01 -8.17459226e-01 ...  1.48839808e+00\n",
      "     1.77421176e+00  3.00474763e-01]\n",
      "   [-1.19990897e+00  4.74455357e-02 -1.45647991e+00 ...  5.57190537e-01\n",
      "     1.49275672e+00 -1.55927256e-01]\n",
      "   [-8.33470106e-01 -5.06230891e-01 -9.00851071e-01 ...  3.00070077e-01\n",
      "     1.25811249e-01  6.74726427e-01]\n",
      "   ...\n",
      "   [ 1.01346433e-01  6.84710667e-02 -3.91578488e-02 ... -6.16800599e-02\n",
      "    -1.30933523e+00  1.73014295e+00]\n",
      "   [ 7.93261766e-01  1.63983151e-01 -5.34738004e-01 ...  1.02636135e+00\n",
      "     1.12305582e+00  2.33507872e-01]\n",
      "   [ 2.11109921e-01  7.34639883e-01 -1.19944446e-01 ... -3.81200522e-01\n",
      "     2.83904791e-01 -1.86199212e+00]]\n",
      "\n",
      "  [[ 1.21437803e-01 -1.31211504e-01 -4.75649834e-01 ... -1.65593088e+00\n",
      "     3.85191262e-01 -1.12849045e+00]\n",
      "   [ 1.05720174e+00 -1.13198924e+00 -1.67343581e+00 ... -1.95780206e+00\n",
      "     1.62641525e+00 -5.99356115e-01]\n",
      "   [ 1.71922237e-01 -8.95583391e-01 -8.97885799e-01 ...  1.19632614e+00\n",
      "     1.17365026e+00 -1.09070468e+00]\n",
      "   ...\n",
      "   [ 2.37085491e-01 -1.02778983e+00 -1.23547423e+00 ... -1.61135495e+00\n",
      "     3.86034638e-01 -1.53226769e-02]\n",
      "   [ 5.68439186e-01 -1.33729780e+00 -4.50892389e-01 ... -1.32790160e+00\n",
      "     1.07627541e-01  2.83813500e+00]\n",
      "   [ 4.08077836e-01  5.81933498e-01 -1.88526785e+00 ...  1.09385931e+00\n",
      "     1.24071908e+00 -1.56251705e+00]]\n",
      "\n",
      "  [[ 1.23828864e+00 -1.74301076e+00  3.13009530e-01 ...  1.46700358e+00\n",
      "     8.39565396e-01  1.05966544e+00]\n",
      "   [-1.09403718e+00  4.95825112e-01 -1.34538496e+00 ... -2.84128594e+00\n",
      "     8.42361152e-01  3.03545833e-01]\n",
      "   [ 2.14419103e+00 -5.02892509e-02  6.11746609e-01 ...  1.68369889e+00\n",
      "    -1.29350078e+00  9.16286767e-01]\n",
      "   ...\n",
      "   [-5.96493542e-01  8.02511573e-01  5.78472972e-01 ... -3.42854202e-01\n",
      "     4.53220636e-01  6.24041140e-01]\n",
      "   [ 5.89621663e-02 -4.12515789e-01 -4.94610727e-01 ...  8.41784179e-01\n",
      "    -1.61483690e-01  5.06769307e-02]\n",
      "   [-1.33960515e-01 -6.66129112e-01 -7.43987799e-01 ...  9.41320300e-01\n",
      "     3.50184888e-01  4.42119002e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.55993208e-01  2.13994205e-01 -8.23612332e-01 ...  8.25188756e-02\n",
      "    -6.17682278e-01  1.40526652e-01]\n",
      "   [ 8.30601037e-01 -8.70107114e-01 -5.42079568e-01 ...  1.26577288e-01\n",
      "     1.06988466e+00 -1.03377771e+00]\n",
      "   [-2.26860896e-01  1.69966608e-01  6.28071129e-01 ...  4.91949856e-01\n",
      "    -9.89661962e-02  3.19794923e-01]\n",
      "   ...\n",
      "   [-2.16067676e-02 -6.84347391e-01 -1.88010797e-01 ... -1.92257151e-01\n",
      "     8.32100868e-01 -1.59469604e-01]\n",
      "   [-9.15564537e-01  5.50970845e-02 -1.30732155e+00 ... -8.26316357e-01\n",
      "    -1.30228114e+00  9.03374493e-01]\n",
      "   [ 3.89083415e-01  9.79279280e-01  3.23897123e-01 ... -1.36959243e+00\n",
      "     1.75859737e+00 -1.71118844e+00]]\n",
      "\n",
      "  [[-8.42531502e-01 -1.28524268e+00 -3.14609647e-01 ... -6.47146940e-01\n",
      "    -4.37447667e-01 -2.10257363e+00]\n",
      "   [-3.56287248e-02 -3.48125994e-01  8.26719701e-01 ... -2.53189772e-01\n",
      "    -1.56286255e-01  9.65916455e-01]\n",
      "   [-1.66109514e+00 -2.50027865e-01  2.27197140e-01 ...  6.92705870e-01\n",
      "    -2.80708849e-01  1.70777321e-01]\n",
      "   ...\n",
      "   [-4.81708825e-01 -1.24506700e+00 -1.47389078e+00 ...  1.17604375e+00\n",
      "    -1.00058353e+00 -9.54830885e-01]\n",
      "   [-7.70607591e-01  1.96326762e-01  1.08619183e-01 ... -9.36949730e-01\n",
      "     7.21099749e-02 -1.77719641e+00]\n",
      "   [-4.11637366e-01  3.16742696e-02 -9.24245417e-01 ... -7.17308879e-01\n",
      "     2.84860969e-01 -1.86710417e-01]]\n",
      "\n",
      "  [[ 6.83829486e-01 -1.37602901e+00 -1.80748850e-01 ... -1.08739591e+00\n",
      "     1.80649185e+00  5.48061192e-01]\n",
      "   [-1.19558311e+00  6.85323298e-01 -1.34224248e+00 ...  8.40879858e-01\n",
      "    -1.56455755e-01 -8.32107186e-01]\n",
      "   [-3.34868479e+00  1.54113662e+00 -1.36704028e+00 ...  9.51363862e-01\n",
      "     3.01871657e-01  7.22832441e-01]\n",
      "   ...\n",
      "   [-6.20512843e-01 -1.55843604e+00  9.43788648e-01 ...  6.40676796e-01\n",
      "    -2.22215220e-01 -1.40626347e+00]\n",
      "   [-7.79689372e-01 -8.28351140e-01 -1.74470925e+00 ...  8.03266168e-01\n",
      "     3.45123857e-01  4.56225097e-01]\n",
      "   [-2.03854156e+00  1.11348414e+00 -7.22094715e-01 ... -1.38217163e+00\n",
      "    -8.70106280e-01  1.27394331e+00]]\n",
      "\n",
      "  [[-1.68338406e+00 -5.04510105e-02 -1.94253480e+00 ... -1.23822653e+00\n",
      "     1.27808785e+00 -2.14931518e-01]\n",
      "   [ 9.56781805e-01 -4.00836140e-01  2.34206751e-01 ...  4.80929434e-01\n",
      "     8.04298162e-01  1.25045449e-01]\n",
      "   [ 2.70220131e-01  1.52986932e+00  4.90262866e-01 ... -5.38201928e-01\n",
      "     6.09859705e-01  1.06924331e+00]\n",
      "   ...\n",
      "   [ 8.98865521e-01 -7.70695329e-01  2.40034550e-01 ...  7.68571496e-01\n",
      "    -2.99913645e-01  1.28599322e+00]\n",
      "   [ 2.63690770e-01  6.43880427e-01 -7.97040641e-01 ... -3.56699437e-01\n",
      "     9.32870924e-01 -8.19874227e-01]\n",
      "   [ 1.81082904e+00 -5.12367904e-01 -1.61314857e+00 ... -3.52347910e-01\n",
      "     8.31063390e-02 -3.85905147e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-1.57877192e-01 -5.49787283e-01 -8.18464577e-01 ... -7.28264332e-01\n",
      "     1.90087587e-01  1.40671766e+00]\n",
      "   [-1.12884629e+00 -3.95837836e-02  8.86788189e-01 ...  1.95810258e-01\n",
      "     3.53473425e-01 -1.45744967e+00]\n",
      "   [ 4.33365673e-01 -1.65569246e-01 -6.81810737e-01 ...  2.59642065e-01\n",
      "    -1.31574166e+00  4.96401161e-01]\n",
      "   ...\n",
      "   [-3.86506498e-01  2.14416909e+00 -2.66146898e-01 ...  4.80109692e-01\n",
      "    -1.39221936e-01 -1.04554200e+00]\n",
      "   [ 3.37106735e-01 -1.57121634e+00 -1.46156049e+00 ... -3.42433572e-01\n",
      "    -1.11988783e+00 -1.03629386e+00]\n",
      "   [-1.25999236e+00  5.70516586e-01 -1.74554670e+00 ... -2.47134417e-01\n",
      "    -4.86586213e-01 -1.05250776e+00]]\n",
      "\n",
      "  [[-1.20291151e-01 -6.67480230e-01 -2.42760792e-01 ...  3.04610252e-01\n",
      "    -1.54554892e+00 -3.99642915e-01]\n",
      "   [ 4.79711482e-04 -4.73919995e-02  3.65501106e-01 ...  3.80278111e-01\n",
      "    -1.41044772e+00  1.93955287e-01]\n",
      "   [ 6.08919978e-01 -2.36445785e-01  6.58609629e-01 ...  9.71067622e-02\n",
      "     3.11744362e-01  1.23334074e+00]\n",
      "   ...\n",
      "   [ 4.11500901e-01  6.51512265e-01  3.22156429e-01 ... -2.87885725e-01\n",
      "    -9.32218909e-01  2.76365727e-01]\n",
      "   [ 3.91381741e-01 -1.29029310e+00  5.52923203e-01 ... -5.45540154e-01\n",
      "     1.42662024e+00  5.97750366e-01]\n",
      "   [ 3.21459025e-01 -1.59794283e+00 -1.97096258e-01 ... -5.46794474e-01\n",
      "    -1.48309362e+00  6.84072554e-01]]\n",
      "\n",
      "  [[-6.66989982e-01  1.77994847e-01  6.90747440e-01 ...  9.83728766e-01\n",
      "    -2.03637302e-01  2.01449752e-01]\n",
      "   [ 1.65734124e+00  1.18957198e+00  8.15702438e-01 ...  1.60394502e+00\n",
      "     5.34603417e-01  1.10468674e+00]\n",
      "   [ 6.01102412e-01  1.54384005e+00  6.39111817e-01 ...  9.10295725e-01\n",
      "     4.03919905e-01  1.95168102e+00]\n",
      "   ...\n",
      "   [-8.45740363e-02  4.10763115e-01  8.01730573e-01 ...  8.25087309e-01\n",
      "    -8.83947492e-01  1.33198798e+00]\n",
      "   [-9.20221746e-01  4.63066958e-02 -8.13959241e-01 ... -3.38749796e-01\n",
      "     5.30810714e-01 -3.52213643e-02]\n",
      "   [ 2.18816566e+00 -8.21559489e-01  2.95529693e-01 ...  1.20378804e+00\n",
      "     3.23187262e-01 -9.83769894e-01]]\n",
      "\n",
      "  [[-2.55269504e+00 -4.97556537e-01  3.67860705e-01 ... -2.26518369e+00\n",
      "     6.20967448e-02  1.58699024e+00]\n",
      "   [ 3.55377525e-01 -1.06339252e+00 -1.63694870e+00 ... -8.72516036e-02\n",
      "     5.10518253e-01  2.64162093e-01]\n",
      "   [ 1.23716068e+00  2.44021386e-01 -1.59335092e-01 ...  9.17425752e-02\n",
      "    -8.63891721e-01 -2.07314897e+00]\n",
      "   ...\n",
      "   [-1.17138447e-02  4.14773285e-01 -1.18213582e+00 ...  4.34012294e-01\n",
      "     4.73005503e-01  8.17836165e-01]\n",
      "   [ 6.96737349e-01  5.07900894e-01 -5.14378361e-02 ... -1.20013022e+00\n",
      "     3.12704355e-01  4.41135049e-01]\n",
      "   [ 5.28201520e-01 -1.07409656e+00  2.20676288e-01 ... -1.83480191e+00\n",
      "    -2.23018974e-01  1.02809083e+00]]]\n",
      "\n",
      "\n",
      " [[[-5.15870631e-01  1.59725082e+00  7.21069455e-01 ...  8.90982509e-01\n",
      "    -1.58951175e+00 -2.06132662e-02]\n",
      "   [-1.91777134e+00  5.11279523e-01 -4.40935880e-01 ...  9.68724847e-01\n",
      "     6.56815886e-01  3.81063819e-01]\n",
      "   [ 8.15075576e-01  1.05602932e+00 -9.33522105e-01 ...  2.05206811e-01\n",
      "     5.86297452e-01  5.31666100e-01]\n",
      "   ...\n",
      "   [-1.19376075e+00  1.47367167e+00 -3.35052133e-01 ... -1.90535158e-01\n",
      "     1.82402417e-01 -8.31831276e-01]\n",
      "   [ 1.04116786e+00  1.22381635e-01  3.08765739e-01 ... -1.40418077e+00\n",
      "    -2.59987742e-01  3.57537538e-01]\n",
      "   [-5.86932480e-01 -1.29008457e-01 -5.39273202e-01 ... -3.21049213e-01\n",
      "     8.44081044e-01 -4.18412209e-01]]\n",
      "\n",
      "  [[ 1.91967201e+00  4.55659032e-01 -6.60550475e-01 ...  1.03375590e+00\n",
      "    -5.58523946e-02 -8.68506208e-02]\n",
      "   [-2.92326450e-01  9.31976914e-01  9.26619470e-01 ... -1.06359765e-01\n",
      "    -2.58343399e-01 -6.52532041e-01]\n",
      "   [ 5.55074453e-01  8.81209433e-01 -4.51292694e-01 ... -2.23676693e-02\n",
      "     1.06611758e-01 -6.92598641e-01]\n",
      "   ...\n",
      "   [-4.15655941e-01 -1.04283937e-03  1.03387225e+00 ...  6.38492405e-01\n",
      "    -1.85576349e-01 -4.82192189e-02]\n",
      "   [-3.62189591e-01  1.19482124e+00 -3.53520066e-02 ... -7.54112080e-02\n",
      "     5.52846193e-01  8.94317389e-01]\n",
      "   [-3.40602279e-01  1.58671367e+00  6.62941873e-01 ... -8.75532106e-02\n",
      "     2.55519032e-01 -7.45983243e-01]]\n",
      "\n",
      "  [[-1.58331001e+00  1.28506160e+00  8.62200618e-01 ...  2.19617367e-01\n",
      "    -1.16156447e+00 -4.24038649e-01]\n",
      "   [ 6.48150742e-01 -6.91356540e-01 -7.80577585e-02 ... -1.64335001e+00\n",
      "     3.98334056e-01 -4.56309527e-01]\n",
      "   [-1.24909498e-01 -5.25873423e-01 -7.22817361e-01 ... -1.70293331e+00\n",
      "     1.27920580e+00 -1.37568307e+00]\n",
      "   ...\n",
      "   [-1.28275287e+00 -1.22308910e+00  1.29156661e+00 ...  5.25921464e-01\n",
      "    -1.19015098e+00  8.48085999e-01]\n",
      "   [ 1.71953261e-01  9.31434214e-01 -6.51354313e-01 ... -6.34202600e-01\n",
      "    -1.46712959e-01 -4.71740253e-02]\n",
      "   [-3.29874933e-01  1.28220034e+00  6.13517582e-01 ... -5.96646309e-01\n",
      "    -1.01466310e+00  4.81662542e-01]]\n",
      "\n",
      "  [[ 3.27210188e+00 -3.28327298e+00  2.48694777e-01 ... -1.08958352e+00\n",
      "    -9.21297252e-01 -1.01547980e+00]\n",
      "   [-3.12742591e-01  4.97433335e-01  1.59855545e+00 ...  1.42631733e+00\n",
      "     4.07003582e-01 -8.07479203e-01]\n",
      "   [-4.16817367e-01  8.82601365e-02 -5.63350916e-01 ... -2.94786870e-01\n",
      "    -2.33953619e+00 -6.71070397e-01]\n",
      "   ...\n",
      "   [ 9.84974980e-01  1.02058685e+00 -1.99528202e-01 ... -5.30477464e-01\n",
      "     1.09236848e+00 -7.81468570e-01]\n",
      "   [-2.12276506e+00 -8.98393035e-01 -1.49678719e+00 ... -6.48419857e-01\n",
      "    -4.71551985e-01 -2.55267650e-01]\n",
      "   [ 1.19231796e+00 -6.75619364e-01  1.99518025e+00 ...  1.57969558e+00\n",
      "    -2.13153377e-01 -4.59323436e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.04541774e-02 -3.09408635e-01 -8.92866731e-01 ... -1.18699682e+00\n",
      "    -6.66839719e-01  4.82317090e-01]\n",
      "   [ 4.97170500e-02  7.95664117e-02  3.56743395e-01 ... -6.54189587e-01\n",
      "    -2.51281351e-01  1.28323233e+00]\n",
      "   [ 1.21045792e+00 -5.00653684e-01 -3.90397966e-01 ...  7.69184709e-01\n",
      "     1.10438740e+00  1.21460664e+00]\n",
      "   ...\n",
      "   [-1.40321016e-01 -6.05551362e-01 -3.31741273e-01 ...  8.68855789e-02\n",
      "    -9.86217141e-01  1.34699523e+00]\n",
      "   [ 8.47166002e-01  5.90082347e-01 -1.23525195e-01 ...  4.10053343e-01\n",
      "    -1.78814280e+00 -1.33420265e+00]\n",
      "   [ 1.44379222e+00 -1.88945854e+00 -5.01661040e-02 ... -7.14081228e-01\n",
      "    -9.87052739e-01 -8.08382809e-01]]\n",
      "\n",
      "  [[ 4.23750371e-01 -3.26675177e-01 -4.65744346e-01 ... -6.96518794e-02\n",
      "     1.25716522e-01 -8.30263495e-01]\n",
      "   [-5.69563270e-01  2.26491734e-01  3.26306522e-01 ... -1.65540040e-01\n",
      "    -2.76286364e+00 -1.50839627e-01]\n",
      "   [-8.31021667e-01 -3.60403091e-01 -1.06399035e+00 ... -1.87224537e-01\n",
      "    -6.69995308e-01 -1.06169057e+00]\n",
      "   ...\n",
      "   [-5.88377342e-02 -1.07590306e+00 -1.47568715e+00 ... -1.97091413e+00\n",
      "     1.09106004e+00  9.43995833e-01]\n",
      "   [ 8.15598369e-01  1.92021918e+00 -1.47488570e+00 ...  6.35287106e-01\n",
      "    -1.08201516e+00 -2.62604070e+00]\n",
      "   [ 1.63123178e+00 -6.42144024e-01 -6.50830269e-01 ...  6.56209767e-01\n",
      "    -2.17484379e+00 -1.51085901e+00]]\n",
      "\n",
      "  [[-6.29602596e-02  1.45230341e+00  4.05496396e-02 ...  5.08318603e-01\n",
      "     1.31142509e+00 -6.68781176e-02]\n",
      "   [ 3.38841006e-02 -8.70872140e-01  5.14702380e-01 ... -1.09260404e+00\n",
      "    -7.89972901e-01 -1.08939135e+00]\n",
      "   [ 1.27741432e+00 -8.26924145e-01 -6.00146294e-01 ...  4.67214167e-01\n",
      "    -1.50504982e+00  7.16164410e-01]\n",
      "   ...\n",
      "   [ 4.85280603e-01 -3.92535180e-01  8.20795059e-01 ...  1.50855505e+00\n",
      "     2.24387407e+00 -4.94735658e-01]\n",
      "   [-2.55720615e+00  5.37829399e-01 -1.70185065e+00 ...  1.03663516e+00\n",
      "     1.36149561e+00 -6.03740275e-01]\n",
      "   [ 7.09571779e-01  6.44653559e-01  1.90875858e-01 ... -4.28259194e-01\n",
      "     2.03736830e+00  1.89075783e-01]]\n",
      "\n",
      "  [[-1.69786835e+00 -1.24812639e+00 -7.02674866e-01 ...  2.05207181e+00\n",
      "    -7.41058767e-01 -7.30895460e-01]\n",
      "   [ 1.18962908e+00 -6.82594121e-01  1.72126639e+00 ...  8.56459558e-01\n",
      "    -2.64138639e-01  2.60469890e+00]\n",
      "   [ 3.25998485e-01  1.76308990e+00 -6.87361002e-01 ... -2.18509626e+00\n",
      "    -1.07573235e+00 -6.83416188e-01]\n",
      "   ...\n",
      "   [ 4.60282594e-01 -2.75155306e-01 -1.49512691e-02 ... -5.49025953e-01\n",
      "    -9.17561829e-01 -7.28550673e-01]\n",
      "   [-1.63211942e+00  8.35276723e-01  8.42458189e-01 ...  4.68498379e-01\n",
      "     1.40308213e+00 -1.12666345e+00]\n",
      "   [ 1.37122065e-01  3.88864666e-01 -8.10467079e-02 ...  1.85998052e-01\n",
      "     1.62453341e+00 -1.43504429e+00]]]], shape=(64, 4, 40, 40), dtype=float32)\n",
      "attention_weights= tf.Tensor(\n",
      "[[[[0.00415554 0.02837937 0.05348304 ... 0.0287716  0.11059438\n",
      "    0.00221842]\n",
      "   [0.00489787 0.01999114 0.01497997 ... 0.01878781 0.03074851\n",
      "    0.02716992]\n",
      "   [0.00407911 0.04369101 0.00154777 ... 0.01615779 0.00402444\n",
      "    0.0224423 ]\n",
      "   ...\n",
      "   [0.04419784 0.0074744  0.01311383 ... 0.01073183 0.00681011\n",
      "    0.03219412]\n",
      "   [0.00682331 0.02683243 0.01821166 ... 0.0286503  0.03893384\n",
      "    0.02892067]\n",
      "   [0.00489653 0.01133044 0.00548565 ... 0.02103752 0.04491235\n",
      "    0.03299574]]\n",
      "\n",
      "  [[0.00407059 0.04487183 0.00912149 ... 0.05386073 0.00667868\n",
      "    0.01716425]\n",
      "   [0.02978059 0.01781442 0.04910877 ... 0.04050929 0.01825878\n",
      "    0.00542507]\n",
      "   [0.12730363 0.00571051 0.06493364 ... 0.0239573  0.01470869\n",
      "    0.00938309]\n",
      "   ...\n",
      "   [0.01387771 0.01588445 0.03354654 ... 0.02212405 0.01289933\n",
      "    0.03441472]\n",
      "   [0.04639482 0.01464442 0.00412861 ... 0.01033191 0.00391508\n",
      "    0.02416772]\n",
      "   [0.0152466  0.0050602  0.00911643 ... 0.01082056 0.01125884\n",
      "    0.04528921]]\n",
      "\n",
      "  [[0.03232962 0.0287318  0.0155094  ... 0.00244882 0.00754276\n",
      "    0.00281635]\n",
      "   [0.01147656 0.01082473 0.01784591 ... 0.01010873 0.00838803\n",
      "    0.0165988 ]\n",
      "   [0.01561741 0.01353589 0.008177   ... 0.04059647 0.00109752\n",
      "    0.03606052]\n",
      "   ...\n",
      "   [0.02647823 0.0259202  0.01612309 ... 0.06582882 0.00518057\n",
      "    0.00182585]\n",
      "   [0.03522966 0.04484814 0.00872057 ... 0.01475296 0.00798303\n",
      "    0.03292771]\n",
      "   [0.00296859 0.01529169 0.01150178 ... 0.03477471 0.01521144\n",
      "    0.13315003]]\n",
      "\n",
      "  [[0.00696657 0.00962199 0.01556915 ... 0.01729815 0.00692684\n",
      "    0.02893574]\n",
      "   [0.02387764 0.01588477 0.03582563 ... 0.01482096 0.00667795\n",
      "    0.00826093]\n",
      "   [0.01635876 0.04320157 0.0286428  ... 0.01084028 0.00879248\n",
      "    0.03120659]\n",
      "   ...\n",
      "   [0.01877404 0.01203449 0.01438376 ... 0.00809571 0.09665175\n",
      "    0.04980418]\n",
      "   [0.00652586 0.00562247 0.00636543 ... 0.01485795 0.01356706\n",
      "    0.04233618]\n",
      "   [0.01749489 0.05035001 0.02365961 ... 0.01192026 0.04438952\n",
      "    0.00520145]]]\n",
      "\n",
      "\n",
      " [[[0.01554359 0.02923516 0.01302176 ... 0.00964505 0.05304582\n",
      "    0.01950879]\n",
      "   [0.0468219  0.00479011 0.04516579 ... 0.02072837 0.02055213\n",
      "    0.04882911]\n",
      "   [0.14118984 0.009194   0.02254242 ... 0.0330168  0.02346792\n",
      "    0.00566267]\n",
      "   ...\n",
      "   [0.02801322 0.01088457 0.03408581 ... 0.01868906 0.00848004\n",
      "    0.01581997]\n",
      "   [0.00879081 0.00644349 0.0047306  ... 0.00526953 0.00699306\n",
      "    0.03016765]\n",
      "   [0.02530234 0.00454474 0.03585666 ... 0.00876408 0.01089257\n",
      "    0.00818807]]\n",
      "\n",
      "  [[0.03713482 0.01312805 0.00797635 ... 0.08002494 0.10650076\n",
      "    0.0243959 ]\n",
      "   [0.00478824 0.01666844 0.00370466 ... 0.02775073 0.07072706\n",
      "    0.01360101]\n",
      "   [0.00878555 0.01218673 0.00821307 ... 0.0272935  0.02292871\n",
      "    0.03969816]\n",
      "   ...\n",
      "   [0.01641721 0.01588626 0.01426524 ... 0.01394755 0.00400542\n",
      "    0.08369059]\n",
      "   [0.04483473 0.02389584 0.01188151 ... 0.05660417 0.06235083\n",
      "    0.02561631]\n",
      "   [0.01914577 0.0323176  0.01374985 ... 0.01058853 0.02059147\n",
      "    0.00240844]]\n",
      "\n",
      "  [[0.02068206 0.01606459 0.01138366 ... 0.00349697 0.02692405\n",
      "    0.00592593]\n",
      "   [0.04668009 0.00522851 0.0030425  ... 0.00228946 0.08247797\n",
      "    0.00890631]\n",
      "   [0.02033687 0.00699314 0.00697706 ... 0.05664703 0.05537696\n",
      "    0.0057535 ]\n",
      "   ...\n",
      "   [0.02312115 0.00652651 0.00530255 ... 0.00364118 0.02683473\n",
      "    0.01796346]\n",
      "   [0.02107826 0.00313461 0.00760579 ... 0.0031642  0.01329557\n",
      "    0.20396286]\n",
      "   [0.02484839 0.02956669 0.0025079  ... 0.04933207 0.05713599\n",
      "    0.00346322]]\n",
      "\n",
      "  [[0.05805794 0.0029451  0.02301537 ... 0.07297789 0.03896712\n",
      "    0.04856088]\n",
      "   [0.00497806 0.02440777 0.00387169 ... 0.00086744 0.03451651\n",
      "    0.02013828]\n",
      "   [0.1104978  0.01231127 0.0238683  ... 0.06972113 0.00355126\n",
      "    0.03236545]\n",
      "   ...\n",
      "   [0.00768685 0.03114073 0.0248903  ... 0.0099061  0.02196007\n",
      "    0.02605074]\n",
      "   [0.01753421 0.01094274 0.01008028 ... 0.03835849 0.01406526\n",
      "    0.01738954]\n",
      "   [0.01448697 0.00850863 0.0078713  ... 0.04245865 0.02350928\n",
      "    0.02577305]]]\n",
      "\n",
      "\n",
      " [[[0.02291021 0.03316749 0.0117513  ... 0.02908129 0.01443843\n",
      "    0.03081811]\n",
      "   [0.04449399 0.00812257 0.01127597 ... 0.02200633 0.05652244\n",
      "    0.00689623]\n",
      "   [0.02022745 0.03008023 0.04755908 ... 0.04150656 0.02298715\n",
      "    0.03494224]\n",
      "   ...\n",
      "   [0.01186153 0.00611387 0.01004321 ... 0.01000065 0.02785488\n",
      "    0.01033398]\n",
      "   [0.00696861 0.01839498 0.00470986 ... 0.00761914 0.00473366\n",
      "    0.04296367]\n",
      "   [0.02237394 0.04037023 0.02096198 ... 0.00385442 0.08800651\n",
      "    0.00273909]]\n",
      "\n",
      "  [[0.00571918 0.00367339 0.00969632 ... 0.00695325 0.0085755\n",
      "    0.0016222 ]\n",
      "   [0.01790705 0.01310111 0.04241672 ... 0.01440583 0.01587169\n",
      "    0.04875167]\n",
      "   [0.00292111 0.01197752 0.01930293 ... 0.03074617 0.01161562\n",
      "    0.01824401]\n",
      "   ...\n",
      "   [0.00950045 0.00442815 0.00352245 ... 0.04985364 0.00565457\n",
      "    0.00591929]\n",
      "   [0.00758572 0.01994946 0.01827428 ... 0.00642326 0.01761913\n",
      "    0.0027723 ]\n",
      "   [0.01101637 0.01716194 0.00659805 ... 0.00811497 0.0221067\n",
      "    0.01379504]]\n",
      "\n",
      "  [[0.02906705 0.00370523 0.01224389 ... 0.00494501 0.08932375\n",
      "    0.02537684]\n",
      "   [0.00532358 0.03491971 0.00459738 ... 0.04079699 0.01504841\n",
      "    0.007657  ]\n",
      "   [0.00060475 0.08038902 0.00438724 ... 0.04457196 0.02328042\n",
      "    0.03546596]\n",
      "   ...\n",
      "   [0.00581726 0.00227711 0.02780266 ... 0.02053272 0.00866358\n",
      "    0.00265138]\n",
      "   [0.00565902 0.00539023 0.00215595 ... 0.02755561 0.01742774\n",
      "    0.01947565]\n",
      "   [0.0026045  0.06090211 0.00971517 ... 0.00502091 0.00837857\n",
      "    0.07150211]]\n",
      "\n",
      "  [[0.00217494 0.01113324 0.00167842 ... 0.00339451 0.04203381\n",
      "    0.00944471]\n",
      "   [0.04854048 0.01248815 0.02356642 ... 0.03016088 0.04167554\n",
      "    0.02112932]\n",
      "   [0.01539049 0.05423893 0.01917855 ... 0.0068574  0.02161504\n",
      "    0.03421872]\n",
      "   ...\n",
      "   [0.04492163 0.00846008 0.02324496 ... 0.03943388 0.01354666\n",
      "    0.06615809]\n",
      "   [0.01923149 0.02812724 0.00665799 ... 0.01034144 0.03755209\n",
      "    0.00650769]\n",
      "   [0.09340925 0.00915036 0.00304351 ... 0.01073826 0.01659776\n",
      "    0.0103839 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.01467162 0.00991456 0.00757859 ... 0.00829396 0.02077769\n",
      "    0.07014115]\n",
      "   [0.00591714 0.01758621 0.044411   ... 0.02225373 0.02605403\n",
      "    0.00425992]\n",
      "   [0.02199408 0.01208347 0.00721092 ... 0.01848667 0.00382541\n",
      "    0.02342512]\n",
      "   ...\n",
      "   [0.01100298 0.13821931 0.01241028 ... 0.02617441 0.01408979\n",
      "    0.00569239]\n",
      "   [0.0329893  0.00489327 0.00546037 ... 0.01672063 0.00768437\n",
      "    0.00835435]\n",
      "   [0.00533385 0.03326752 0.00328221 ... 0.01468652 0.01155916\n",
      "    0.00656372]]\n",
      "\n",
      "  [[0.01652092 0.00955857 0.01461659 ... 0.02526774 0.0039724\n",
      "    0.01249434]\n",
      "   [0.01607893 0.01532734 0.02316243 ... 0.02350724 0.00392193\n",
      "    0.01951114]\n",
      "   [0.03479135 0.01493942 0.0365638  ... 0.02085421 0.02584697\n",
      "    0.06496117]\n",
      "   ...\n",
      "   [0.0292604  0.03719768 0.02675953 ... 0.0145392  0.00763326\n",
      "    0.02556182]\n",
      "   [0.02894203 0.00538502 0.03401618 ... 0.01134042 0.08149432\n",
      "    0.03557573]\n",
      "   [0.02250874 0.00330191 0.01340125 ... 0.00944656 0.00370377\n",
      "    0.03234687]]\n",
      "\n",
      "  [[0.00780227 0.01816324 0.03033045 ... 0.04065548 0.01240088\n",
      "    0.01859429]\n",
      "   [0.04296923 0.02691585 0.0185199  ... 0.04073502 0.01398166\n",
      "    0.02472537]\n",
      "   [0.02332465 0.05987436 0.02422827 ... 0.03177577 0.01915049\n",
      "    0.09002518]\n",
      "   ...\n",
      "   [0.0147759  0.02424801 0.03584851 ... 0.03669567 0.0066434\n",
      "    0.06091986]\n",
      "   [0.00826455 0.02172588 0.00919112 ... 0.01478255 0.03526913\n",
      "    0.02002489]\n",
      "   [0.08887138 0.00438182 0.01339061 ... 0.03320872 0.01376614\n",
      "    0.0037257 ]]\n",
      "\n",
      "  [[0.00162135 0.01265934 0.03007855 ... 0.00216143 0.02215468\n",
      "    0.10179307]\n",
      "   [0.01792898 0.00433902 0.00244512 ... 0.0115166  0.02093787\n",
      "    0.01636595]\n",
      "   [0.0567456  0.02101926 0.01404241 ... 0.01805026 0.00694156\n",
      "    0.00207149]\n",
      "   ...\n",
      "   [0.0129213  0.01979372 0.00400865 ... 0.02017821 0.02098057\n",
      "    0.02961933]\n",
      "   [0.04059536 0.03360979 0.01921092 ... 0.00609084 0.02764987\n",
      "    0.03143907]\n",
      "   [0.02618876 0.00527528 0.01925566 ... 0.00246533 0.01235561\n",
      "    0.04317319]]]\n",
      "\n",
      "\n",
      " [[[0.00945213 0.07820717 0.03256311 ... 0.03859385 0.00323038\n",
      "    0.01551019]\n",
      "   [0.0020603  0.02338054 0.0090222  ... 0.03694201 0.02704333\n",
      "    0.02052592]\n",
      "   [0.0426043  0.05421236 0.00741391 ... 0.02315212 0.03389193\n",
      "    0.03209004]\n",
      "   ...\n",
      "   [0.00310442 0.04471272 0.00732676 ... 0.00846594 0.01229249\n",
      "    0.00445824]\n",
      "   [0.05140004 0.02050878 0.02471071 ... 0.00445617 0.01399197\n",
      "    0.02594577]\n",
      "   [0.0082408  0.01302697 0.00864306 ... 0.01075081 0.03447076\n",
      "    0.00975342]]\n",
      "\n",
      "  [[0.11031328 0.02551614 0.00835702 ... 0.04548617 0.01529919\n",
      "    0.01483222]\n",
      "   [0.01025764 0.0348944  0.03470796 ... 0.01235412 0.01061222\n",
      "    0.00715504]\n",
      "   [0.02242615 0.03107372 0.00819775 ... 0.01258852 0.01432154\n",
      "    0.00644017]\n",
      "   ...\n",
      "   [0.01442026 0.02182917 0.06144623 ... 0.04137937 0.01815079\n",
      "    0.02082327]\n",
      "   [0.0148825  0.07061179 0.02063573 ... 0.01982542 0.0371596\n",
      "    0.05228415]\n",
      "   [0.01119997 0.07695545 0.03055276 ... 0.01442496 0.02032867\n",
      "    0.00746727]]\n",
      "\n",
      "  [[0.00266802 0.04697943 0.0307795  ... 0.01618793 0.00406772\n",
      "    0.00850462]\n",
      "   [0.03799456 0.00995361 0.01837947 ... 0.0038418  0.02959562\n",
      "    0.01259101]\n",
      "   [0.01517075 0.01015946 0.00834332 ... 0.00313098 0.0617741\n",
      "    0.00434313]\n",
      "   ...\n",
      "   [0.00174722 0.00185463 0.02292765 ... 0.01066213 0.00191674\n",
      "    0.01471493]\n",
      "   [0.01551507 0.03315828 0.00681076 ... 0.00692859 0.01128129\n",
      "    0.01246201]\n",
      "   [0.01273724 0.0638544  0.03271791 ... 0.00975479 0.00642208\n",
      "    0.02867621]]\n",
      "\n",
      "  [[0.25229764 0.00035888 0.01227056 ... 0.00321853 0.00380841\n",
      "    0.00346609]\n",
      "   [0.01087929 0.02445995 0.07356425 ... 0.06192482 0.02234511\n",
      "    0.00663345]\n",
      "   [0.01310172 0.02171105 0.01131592 ... 0.01480218 0.00191559\n",
      "    0.01016033]\n",
      "   ...\n",
      "   [0.03698417 0.03832498 0.01131339 ... 0.00812575 0.04117715\n",
      "    0.00632207]\n",
      "   [0.00264601 0.00900179 0.00494823 ... 0.01155822 0.01379442\n",
      "    0.01712516]\n",
      "   [0.04428705 0.00683978 0.09884515 ... 0.06523981 0.01086146\n",
      "    0.00849137]]]\n",
      "\n",
      "\n",
      " [[[0.01374616 0.00978545 0.00545994 ... 0.00406864 0.00684464\n",
      "    0.02159847]\n",
      "   [0.01455253 0.01499346 0.01978237 ... 0.0071984  0.01077002\n",
      "    0.04996286]\n",
      "   [0.06258187 0.01130635 0.01262425 ... 0.04025372 0.05628371\n",
      "    0.06284204]\n",
      "   ...\n",
      "   [0.01393552 0.00875137 0.01150775 ... 0.01749032 0.00598074\n",
      "    0.0616675 ]\n",
      "   [0.02190593 0.01693993 0.00829843 ... 0.01414901 0.00157059\n",
      "    0.00247289]\n",
      "   [0.06179002 0.00220448 0.01387076 ... 0.00714111 0.0054352\n",
      "    0.00649847]]\n",
      "\n",
      "  [[0.02974872 0.01404632 0.01222266 ... 0.01816295 0.02208177\n",
      "    0.00848901]\n",
      "   [0.01022142 0.02265863 0.02503702 ... 0.01531004 0.00114018\n",
      "    0.01553677]\n",
      "   [0.00646495 0.01035028 0.00512139 ... 0.0123073  0.00759448\n",
      "    0.00513318]\n",
      "   ...\n",
      "   [0.01634661 0.00591183 0.00396367 ... 0.00241559 0.05162048\n",
      "    0.04456079]\n",
      "   [0.03851802 0.11625046 0.0038987  ... 0.03216294 0.00577485\n",
      "    0.00123305]\n",
      "   [0.07112609 0.00732343 0.00726009 ... 0.02682762 0.00158151\n",
      "    0.00307211]]\n",
      "\n",
      "  [[0.01251564 0.05695391 0.01388055 ... 0.02215931 0.04946988\n",
      "    0.0124667 ]\n",
      "   [0.01475361 0.00596991 0.02386245 ... 0.00478267 0.00647294\n",
      "    0.00479806]\n",
      "   [0.05132722 0.00625814 0.00785115 ... 0.02282876 0.00317643\n",
      "    0.02928195]\n",
      "   ...\n",
      "   [0.02374329 0.00986984 0.03320878 ... 0.06606071 0.13781239\n",
      "    0.00891097]\n",
      "   [0.00134083 0.02961624 0.00315391 ... 0.04877065 0.06749065\n",
      "    0.00945698]\n",
      "   [0.02907701 0.02724935 0.01730944 ... 0.00931957 0.10969945\n",
      "    0.01727831]]\n",
      "\n",
      "  [[0.00281729 0.00441724 0.00762146 ... 0.11978688 0.00733446\n",
      "    0.00740938]\n",
      "   [0.04659054 0.00716476 0.07928388 ... 0.03338905 0.01088766\n",
      "    0.19180271]\n",
      "   [0.02161504 0.09096552 0.0078462  ... 0.00175469 0.00532098\n",
      "    0.00787722]\n",
      "   ...\n",
      "   [0.02606456 0.01249263 0.01620537 ... 0.00949977 0.00657143\n",
      "    0.00793865]\n",
      "   [0.00243859 0.02875512 0.02896236 ... 0.01992624 0.05073525\n",
      "    0.00404255]\n",
      "   [0.01363951 0.01754402 0.01096602 ... 0.01432271 0.06036333\n",
      "    0.00283149]]]], shape=(64, 4, 40, 40), dtype=float32)\n",
      "value.shape= (64, 4, 40, 32)\n",
      "value= tf.Tensor(\n",
      "[[[[ 0.7147506  -0.25899115  0.58899    ...  0.00416013  0.22062397\n",
      "     0.5034513 ]\n",
      "   [ 0.00566529 -1.8195332  -1.3264114  ...  0.49933594 -1.2964377\n",
      "    -1.1816717 ]\n",
      "   [ 0.02292592  0.78830636 -0.8205126  ... -0.21167742 -0.3572851\n",
      "     0.44426408]\n",
      "   ...\n",
      "   [-0.35842255  0.55765027 -1.3945203  ...  0.7152498  -0.5196283\n",
      "     1.8576456 ]\n",
      "   [-1.1375166   0.2000911  -0.7407844  ... -0.41485348  1.0285605\n",
      "     1.9740636 ]\n",
      "   [-0.6042697  -0.37692645 -0.05245341 ... -0.5677477  -1.3050939\n",
      "    -0.3606403 ]]\n",
      "\n",
      "  [[-0.8096407   0.7949734  -0.11189362 ... -0.36164212  1.0331521\n",
      "     0.54796505]\n",
      "   [-0.31128094  0.31946063 -0.5326935  ...  0.08816994 -0.99644667\n",
      "     0.99013096]\n",
      "   [-0.60755634  0.91518575 -1.1394682  ... -0.4715476  -0.64439136\n",
      "    -1.5331559 ]\n",
      "   ...\n",
      "   [-1.6397586  -0.21189426 -0.6954551  ... -0.14296305  0.7457654\n",
      "    -0.69148576]\n",
      "   [-1.0919819   0.33158207 -1.0289576  ...  0.80504215 -1.3021282\n",
      "     0.31002042]\n",
      "   [-0.97723097 -1.5997249   0.08508004 ... -1.0642291  -0.8221934\n",
      "     0.6870056 ]]\n",
      "\n",
      "  [[-1.5335926   0.78899497 -1.0900311  ... -1.8635656   0.48275667\n",
      "    -1.2448757 ]\n",
      "   [ 0.18585496  0.71659213 -0.19190758 ...  0.8359786   0.76030385\n",
      "     0.22535838]\n",
      "   [-0.20398904  0.30798212 -0.27299544 ...  1.9513956   0.7494147\n",
      "    -0.5577065 ]\n",
      "   ...\n",
      "   [-1.1899213  -0.0976325  -0.71548694 ...  2.7596703  -0.7201024\n",
      "    -1.2650145 ]\n",
      "   [-0.19371913 -1.3417021   0.33029476 ... -0.44392765 -0.8348534\n",
      "    -1.91344   ]\n",
      "   [-0.8569743  -1.3144531   3.3414888  ...  1.0075656   0.6110148\n",
      "    -0.28883865]]\n",
      "\n",
      "  [[ 1.0951393  -1.1341441  -0.39603552 ...  0.9258403  -0.53126174\n",
      "    -1.0100497 ]\n",
      "   [-1.5448304  -0.23043142 -2.2263925  ...  0.26976502  1.54383\n",
      "    -0.7287894 ]\n",
      "   [-1.5922276  -1.6409262  -0.86514014 ...  0.36011407 -0.3545246\n",
      "    -0.26911297]\n",
      "   ...\n",
      "   [-0.23768668 -0.9902726   1.1141441  ... -1.390542   -0.50508666\n",
      "    -0.3528166 ]\n",
      "   [ 0.8145056  -1.5471858   0.10308976 ...  0.2993294  -0.16605587\n",
      "     0.83330834]\n",
      "   [-0.4676189  -0.7392027   1.6506376  ... -0.7714133   2.2410343\n",
      "     0.2592354 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.55899155 -2.6869833  -0.34988898 ...  1.0859436   0.7156924\n",
      "     0.907244  ]\n",
      "   [-0.49556488 -0.12967123 -0.83005625 ...  0.04397193  0.61899513\n",
      "     0.46413636]\n",
      "   [ 2.0719724   1.1577166   2.5944245  ... -0.46362194  0.23209272\n",
      "    -0.48554206]\n",
      "   ...\n",
      "   [-0.6599351   1.1013021  -0.84025985 ... -1.5658764  -0.44940966\n",
      "     1.6891534 ]\n",
      "   [-0.35609418  1.0527505  -0.95817643 ...  1.2357119   0.35001278\n",
      "    -1.3450941 ]\n",
      "   [ 0.8213579  -0.9924813  -0.33442262 ... -0.16814043 -1.4372637\n",
      "    -0.9867931 ]]\n",
      "\n",
      "  [[-1.0693986  -0.44180796 -0.31336585 ...  1.2789978  -2.0096085\n",
      "     1.1343808 ]\n",
      "   [ 0.4587674   0.70478106  1.5511162  ... -0.08730443  0.96888685\n",
      "    -0.04842535]\n",
      "   [ 1.4782757   0.71727055  0.5000256  ... -1.2542926  -1.3847197\n",
      "    -0.426317  ]\n",
      "   ...\n",
      "   [-0.29400602 -0.25204322 -0.32825884 ... -1.2565691   1.0538105\n",
      "    -0.13855615]\n",
      "   [ 1.1668003  -0.97680724  0.57850206 ... -1.897158   -0.703785\n",
      "    -0.7307727 ]\n",
      "   [ 1.6097573  -1.2868332  -0.5902243  ...  1.1487815   0.03142582\n",
      "    -0.5132612 ]]\n",
      "\n",
      "  [[-0.56066513 -0.12305041 -1.0132132  ... -1.0221792  -1.1018062\n",
      "    -1.5447644 ]\n",
      "   [-1.0133579   1.3586943  -1.4439974  ...  0.34409755  0.17096332\n",
      "    -1.3639774 ]\n",
      "   [ 0.33205342 -0.6144404  -0.37105435 ... -0.32132852  2.555669\n",
      "     1.1409537 ]\n",
      "   ...\n",
      "   [ 1.0422281  -1.1274457  -0.79590654 ...  0.10253654 -0.13489752\n",
      "     0.13183819]\n",
      "   [ 0.6123469   0.7445364   0.8770789  ... -0.5949886  -0.2675066\n",
      "     1.4310635 ]\n",
      "   [ 0.7310227   1.2884879   0.9257524  ...  1.2053211   0.8158732\n",
      "    -0.7611573 ]]\n",
      "\n",
      "  [[ 0.67910916 -1.2254852  -1.5935268  ... -0.43626606 -1.5231194\n",
      "     0.41833943]\n",
      "   [ 0.7601338   0.92510825 -1.1874378  ...  0.96995455 -1.3304509\n",
      "     0.46376622]\n",
      "   [ 0.32912388  0.13302606 -1.0274744  ...  0.466676    0.41617045\n",
      "    -0.02423024]\n",
      "   ...\n",
      "   [-0.44651797 -0.1841     -0.55287653 ...  1.0040605   0.46312666\n",
      "    -1.6587188 ]\n",
      "   [ 1.7582688   0.65485007  2.251386   ... -0.02174558  0.6888105\n",
      "     2.230733  ]\n",
      "   [-0.796611   -0.00675221 -0.4873815  ...  2.5653164   0.00897521\n",
      "    -0.5112802 ]]]\n",
      "\n",
      "\n",
      " [[[-0.14022003  0.86599773  0.22177385 ...  0.34262007 -0.13122332\n",
      "     0.83198965]\n",
      "   [ 0.9583452  -0.88129973 -0.2798603  ... -0.6853598   0.17320596\n",
      "    -0.2141171 ]\n",
      "   [-0.66063005 -0.12180232 -0.27691594 ...  1.1497909  -1.1378977\n",
      "    -0.38834795]\n",
      "   ...\n",
      "   [ 0.41630152  0.46419293  0.96560305 ...  1.2294153   0.5567526\n",
      "    -1.66351   ]\n",
      "   [ 1.9516174  -0.12580718  1.1314964  ... -1.5066254  -0.45943144\n",
      "    -0.27694663]\n",
      "   [-2.078699   -0.5648883   0.210112   ...  0.49422345 -0.23354973\n",
      "     0.14439324]]\n",
      "\n",
      "  [[-0.53399366  1.5820495  -1.2834547  ... -1.0874966   0.24121642\n",
      "    -0.02853407]\n",
      "   [ 1.5969044   0.80078906 -1.2388055  ... -0.47219154  0.9845153\n",
      "    -1.657555  ]\n",
      "   [-0.24121736 -1.0784494  -0.32892612 ... -1.4247963  -0.29645348\n",
      "     1.2491933 ]\n",
      "   ...\n",
      "   [ 0.5302621  -1.037106    0.8595402  ... -0.46105292  0.28516516\n",
      "    -0.22289304]\n",
      "   [-0.6568461  -0.5760646  -0.44418874 ... -0.15874438 -0.14354907\n",
      "    -0.50147086]\n",
      "   [-1.266284    0.29474714 -0.0035962  ... -0.5755161  -1.4259229\n",
      "     1.4459537 ]]\n",
      "\n",
      "  [[-2.3334517   1.078138    0.42782876 ... -0.00454031 -0.08546446\n",
      "    -0.12745383]\n",
      "   [ 0.33676308  0.7384932  -0.61813676 ...  0.47064447 -0.4980571\n",
      "    -1.1663105 ]\n",
      "   [ 1.7523061  -1.1675181   1.4556783  ... -0.40343392 -0.53321326\n",
      "    -0.17503564]\n",
      "   ...\n",
      "   [-0.7717005  -2.4879255   1.700857   ...  0.3459914   1.7472694\n",
      "     0.21979992]\n",
      "   [-0.23083954 -0.2738251  -0.0105945  ...  0.17866197 -0.78608006\n",
      "    -0.2604705 ]\n",
      "   [ 1.0668896  -1.0618066   0.3265327  ... -0.42773458 -1.6781951\n",
      "    -0.06956705]]\n",
      "\n",
      "  [[-0.34424004  1.3426876  -0.508531   ... -2.6018176   2.668329\n",
      "    -1.6285518 ]\n",
      "   [-1.3018707   0.05695386 -1.8047837  ...  0.23886265 -0.40707514\n",
      "     0.47966185]\n",
      "   [ 0.9834319  -0.2691413  -0.1913193  ...  0.22510616  0.35654804\n",
      "    -0.11761051]\n",
      "   ...\n",
      "   [-0.6298247   0.7951632  -0.8617215  ... -0.07874281  0.14382085\n",
      "    -0.43868282]\n",
      "   [-0.90407777  0.6978898  -1.4320083  ...  0.72306764  0.6765617\n",
      "     0.06784606]\n",
      "   [-0.27065104 -2.4922144  -0.54805124 ... -0.10611619  0.5739689\n",
      "     0.380601  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 1.2744704   0.6846877  -0.16430962 ... -0.66839135 -0.9620984\n",
      "    -0.7430991 ]\n",
      "   [-0.63399756  0.74753684 -0.4448869  ... -1.9831198  -0.32355672\n",
      "    -0.3259607 ]\n",
      "   [-1.3045528   1.1932178   0.05094754 ...  0.4007233   1.2190317\n",
      "     0.3982552 ]\n",
      "   ...\n",
      "   [ 0.44561496  0.28798386  1.0708498  ...  0.3891027   0.38005263\n",
      "    -0.79521704]\n",
      "   [-1.0851421  -0.46431676 -0.7203273  ... -0.01575972 -0.18952525\n",
      "    -0.15335025]\n",
      "   [ 1.2313647  -0.44970527  1.4858108  ... -1.9130197  -1.530489\n",
      "    -0.30939215]]\n",
      "\n",
      "  [[ 0.130421    0.7362506  -1.1489979  ... -1.5669577  -1.9510301\n",
      "    -0.98660535]\n",
      "   [-0.1310216  -0.26909867 -0.6485266  ...  0.03037385  1.0833192\n",
      "    -1.5942004 ]\n",
      "   [-0.6897037  -0.86097884 -0.97963774 ...  0.18484265  0.33375445\n",
      "    -0.05666574]\n",
      "   ...\n",
      "   [-1.3543062  -1.1873955   0.746924   ...  1.2465876   0.09428594\n",
      "     1.0667273 ]\n",
      "   [-1.0041046  -0.08292102  1.5655158  ... -1.0762465   0.7708346\n",
      "     1.4354273 ]\n",
      "   [ 0.84407467 -0.9704028   0.12347985 ...  0.03603792 -0.07183643\n",
      "     1.525269  ]]\n",
      "\n",
      "  [[-1.4026196  -0.01463065  0.16131248 ...  0.95417994  0.0330792\n",
      "    -0.24961519]\n",
      "   [ 0.1121612  -0.37920064 -0.4302486  ... -3.0460396   1.7663649\n",
      "     1.03372   ]\n",
      "   [-0.07000159 -0.7412003  -0.09428965 ...  1.424443    1.2352076\n",
      "    -1.4949839 ]\n",
      "   ...\n",
      "   [ 0.6430566  -0.20154662  0.2610854  ... -0.8173169   1.2349459\n",
      "     0.45662045]\n",
      "   [-1.456724    0.20699477 -0.93498075 ... -2.158503    0.44665098\n",
      "    -2.3466232 ]\n",
      "   [ 1.1842313   0.5394196  -0.08923998 ...  0.57415986  0.07334604\n",
      "     0.5183399 ]]\n",
      "\n",
      "  [[-1.2336215   0.03053354 -0.6138815  ...  0.8591564  -0.2123086\n",
      "     0.49221334]\n",
      "   [ 0.3891492   1.0584259   1.0493478  ...  0.6710952  -1.1312685\n",
      "    -0.8222422 ]\n",
      "   [ 1.460326   -0.15330572 -0.6809645  ...  0.12114482 -0.2888331\n",
      "    -0.867174  ]\n",
      "   ...\n",
      "   [ 0.9509152   0.4224692  -0.74987334 ... -0.12627617 -0.05672937\n",
      "     1.0911556 ]\n",
      "   [ 0.07045383 -0.8222861   0.28385723 ... -0.97820824 -0.55546707\n",
      "    -0.87945104]\n",
      "   [-0.24445732 -0.34280533 -0.9458252  ...  0.44324166 -1.4646587\n",
      "     0.7926948 ]]]\n",
      "\n",
      "\n",
      " [[[-1.1914997   0.1019728   1.4973606  ...  0.6037635   0.42952415\n",
      "     0.7928051 ]\n",
      "   [ 0.5737986   0.7110287  -0.35288423 ... -0.28323817  1.2436228\n",
      "    -0.25997669]\n",
      "   [-0.88921106  1.3510071   0.24733306 ... -0.47999397 -0.65143305\n",
      "    -0.98074424]\n",
      "   ...\n",
      "   [ 0.6359474  -0.8513985   0.24266908 ...  1.0506963   0.26532888\n",
      "    -1.0170082 ]\n",
      "   [-1.7676814   0.25872087 -1.1068013  ...  0.1434289  -0.03457108\n",
      "     0.34811428]\n",
      "   [-0.17611581 -1.6487346  -0.4871594  ... -0.19872397 -1.0034951\n",
      "    -0.01181091]]\n",
      "\n",
      "  [[-1.4916098   1.0859183  -0.59896666 ... -0.5336481   0.43819645\n",
      "     0.64762384]\n",
      "   [ 0.22402504  0.11604556  0.43233204 ... -0.9754006   0.08792215\n",
      "    -0.8493406 ]\n",
      "   [ 1.1432345  -0.298727   -0.7949885  ... -1.581294    0.37840062\n",
      "    -0.12261098]\n",
      "   ...\n",
      "   [-0.6547592   0.16161826  0.54844755 ...  0.14893793  0.01851318\n",
      "     0.96594656]\n",
      "   [ 0.05059091 -0.32010186  1.1130656  ...  1.394182    0.85992014\n",
      "    -0.08485045]\n",
      "   [-1.2301846  -0.3988969   1.0688566  ... -0.32185853  0.99233556\n",
      "     0.5752587 ]]\n",
      "\n",
      "  [[-1.8600212  -1.158324    1.0227385  ...  0.889789    1.8107761\n",
      "     1.0879257 ]\n",
      "   [ 0.35923567  2.4430728  -0.645316   ... -0.9430314   0.9109483\n",
      "    -1.4825402 ]\n",
      "   [-0.02003405  0.3426983   1.2441982  ...  0.36653274 -1.5425276\n",
      "     0.36895522]\n",
      "   ...\n",
      "   [-0.20383221 -0.63672924  0.57093847 ...  0.6230475   0.6936495\n",
      "     0.04117352]\n",
      "   [-1.7557067  -0.9852222  -0.15328678 ... -1.2795988  -2.6165285\n",
      "     0.32276258]\n",
      "   [ 1.0648677  -0.19164751 -0.51299876 ... -0.8406615  -0.8525987\n",
      "     0.9493447 ]]\n",
      "\n",
      "  [[ 0.94657874  0.8144994  -3.0679312  ...  1.256162   -0.3962969\n",
      "    -0.04321254]\n",
      "   [ 0.5255411  -1.9186867  -0.17294094 ...  1.7230401   1.4897256\n",
      "    -0.97949153]\n",
      "   [ 0.33717352 -0.18139021  0.12056493 ...  0.218225    2.8547783\n",
      "    -0.4155854 ]\n",
      "   ...\n",
      "   [ 0.77616    -1.1958345  -2.566544   ...  0.6051703   0.04601711\n",
      "     0.1597684 ]\n",
      "   [-0.56341666  1.303476   -0.08318999 ...  0.52065486  1.3611257\n",
      "    -1.2916955 ]\n",
      "   [ 0.6842144  -0.82593125 -0.86515    ...  0.6539867   1.0164895\n",
      "     0.5764243 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.3848135   0.4075691  -0.8539915  ...  0.17732    -1.154662\n",
      "     1.2543695 ]\n",
      "   [ 1.396307    0.5538671  -2.2677522  ... -0.4026439   0.9576991\n",
      "    -1.235113  ]\n",
      "   [ 1.5578839   0.68332034  0.68146974 ...  0.8351554  -0.164533\n",
      "     0.8118169 ]\n",
      "   ...\n",
      "   [ 0.01819012 -0.5081255   0.21214473 ... -0.6534003  -1.022935\n",
      "     0.43510896]\n",
      "   [-0.92832625 -0.9530439   0.26329598 ...  0.8029086   1.0348474\n",
      "    -0.68401253]\n",
      "   [-0.11975272  0.73238397  0.15109709 ...  1.1067683  -0.8596614\n",
      "    -0.01829439]]\n",
      "\n",
      "  [[ 0.7649995   0.51637816 -0.24602883 ...  1.2421476  -1.088922\n",
      "     0.8274122 ]\n",
      "   [ 1.2969626  -0.83123237  0.09890395 ... -0.12286066 -0.90630716\n",
      "     0.41463906]\n",
      "   [-1.3402517   1.0076936  -0.6515552  ... -2.4566731   0.4654267\n",
      "    -0.40979052]\n",
      "   ...\n",
      "   [ 0.78227884 -0.875139    0.69868153 ... -0.11726354  0.4992628\n",
      "    -0.289187  ]\n",
      "   [-0.4793521   1.2839628  -0.684758   ... -0.23861161 -0.09936585\n",
      "    -0.31806868]\n",
      "   [-0.53405595 -0.2501813  -0.3512981  ...  1.2961273   0.9109253\n",
      "    -0.4312749 ]]\n",
      "\n",
      "  [[ 0.10696264  0.58670413  1.2906525  ... -0.01172753 -1.2647822\n",
      "     0.04166144]\n",
      "   [ 1.5232835  -0.24772906 -0.18176106 ...  0.33531258  1.1932367\n",
      "     0.89475816]\n",
      "   [-0.41959998  0.5551659  -0.6535367  ... -1.0022429  -0.6785925\n",
      "     0.36883807]\n",
      "   ...\n",
      "   [ 1.6969885   1.4824858   0.2503829  ... -0.8667379  -0.07347929\n",
      "     0.9808586 ]\n",
      "   [-0.8356378  -0.41987127 -1.0452015  ... -1.2391245   2.1079037\n",
      "    -0.51221246]\n",
      "   [ 0.9063087   0.8865362  -0.65753293 ... -1.2688338  -1.7515148\n",
      "    -0.50903004]]\n",
      "\n",
      "  [[-1.1727695   1.754495   -0.8712118  ...  0.83793056 -0.465987\n",
      "     1.8007225 ]\n",
      "   [-0.1114037   0.15464346  1.6941209  ...  0.20313892 -0.71396303\n",
      "     0.5871183 ]\n",
      "   [ 0.26511747 -0.3169024  -0.7565846  ... -0.10880126  0.6652983\n",
      "    -0.32542887]\n",
      "   ...\n",
      "   [-1.2363755   1.9050136   0.2640308  ... -0.42600828  0.87138224\n",
      "    -0.2041183 ]\n",
      "   [ 0.08794053  0.17777708  0.01159557 ...  0.04967073  1.4164716\n",
      "    -0.7985364 ]\n",
      "   [ 0.16911209 -0.32461852  0.6246135  ... -1.9595184   1.3866994\n",
      "    -1.3629638 ]]]], shape=(64, 4, 40, 32), dtype=float32)\n",
      "output = tf.Tensor(\n",
      "[[[[-0.04051803  0.10080244 -0.04660046 ... -0.19210497  0.08578903\n",
      "     0.26879716]\n",
      "   [-0.20494515 -0.37384418  0.3058084  ...  0.04091166  0.02257344\n",
      "     0.30295172]\n",
      "   [-0.24284707 -0.55548745  0.2557891  ... -0.14792441 -0.04552118\n",
      "     0.6480919 ]\n",
      "   ...\n",
      "   [-0.39984685 -0.5430653   0.18777566 ...  0.21237345 -0.00676273\n",
      "    -0.0707908 ]\n",
      "   [-0.26902676 -0.28729585  0.2562931  ... -0.08995279  0.17312327\n",
      "     0.17467962]\n",
      "   [-0.05837319 -0.14306764  0.39436215 ...  0.02752881  0.1352583\n",
      "     0.24823168]]\n",
      "\n",
      "  [[-0.37909865 -0.1074664  -0.29628202 ...  0.00590659  0.24799208\n",
      "     0.04462511]\n",
      "   [-0.6415549  -0.00242738 -0.06319817 ... -0.08697214  0.7194111\n",
      "    -0.14405833]\n",
      "   [-0.16924322 -0.3038365  -0.4612879  ...  0.29063052 -0.08850591\n",
      "     0.08039705]\n",
      "   ...\n",
      "   [ 0.3392905  -0.13222568 -0.45777407 ... -0.1594626  -0.02502561\n",
      "     0.1971724 ]\n",
      "   [-0.1348954  -0.32232097 -0.16361031 ...  0.25381038  0.05867128\n",
      "    -0.07366472]\n",
      "   [-0.60618645 -0.24375387 -0.08985624 ... -0.1814276   0.7257285\n",
      "     0.1806542 ]]\n",
      "\n",
      "  [[ 0.3533714   0.06488889  0.855095   ...  0.5081493  -0.26813972\n",
      "     0.6548058 ]\n",
      "   [-0.02513958 -0.1647402   0.5726326  ...  0.17387326 -0.02147001\n",
      "     0.286325  ]\n",
      "   [-0.1351818   0.11297338  0.60507333 ...  0.46117583  0.17854016\n",
      "     0.13900058]\n",
      "   ...\n",
      "   [-0.11192335  0.1156561   0.5161918  ...  0.20468564 -0.19510303\n",
      "     0.4491108 ]\n",
      "   [-0.22735684  0.24091838  0.41495952 ...  0.36784038  0.3392082\n",
      "     0.0626998 ]\n",
      "   [-0.25517875 -0.54301643  1.0299786  ...  0.36101016  0.24998617\n",
      "     0.03156329]]\n",
      "\n",
      "  [[-0.6816512   0.07736108 -0.3854058  ... -0.13774951 -0.1116525\n",
      "    -0.25955617]\n",
      "   [-0.15767102 -0.05015839 -0.00119286 ...  0.16418537 -0.26110137\n",
      "    -0.21589522]\n",
      "   [-0.17133716 -0.18275253 -0.12119593 ...  0.14801697 -0.52292\n",
      "    -0.06016361]\n",
      "   ...\n",
      "   [-0.04097551 -0.21648805 -0.10931009 ...  0.08392832 -0.15178262\n",
      "     0.100343  ]\n",
      "   [-0.43501392  0.09522042 -0.2513011  ... -0.16117258 -0.09745789\n",
      "    -0.23623803]\n",
      "   [ 0.0833469  -0.08464339  0.26990777 ...  0.08557232 -0.00394355\n",
      "    -0.34315977]]]\n",
      "\n",
      "\n",
      " [[[-0.14558321  0.07417195  0.381302   ...  0.23881719 -0.11080982\n",
      "     0.023827  ]\n",
      "   [-0.04061434 -0.21529771  0.36076492 ...  0.24789676  0.04378893\n",
      "    -0.10181506]\n",
      "   [ 0.05837006 -0.32673416 -0.16311887 ...  0.20707533  0.2399018\n",
      "     0.13680632]\n",
      "   ...\n",
      "   [ 0.01802564  0.01464354  0.46698305 ...  0.29902253  0.19779313\n",
      "     0.08205903]\n",
      "   [-0.24485384  0.2152349   0.18848993 ...  0.11176259  0.26654172\n",
      "    -0.31763178]\n",
      "   [-0.11097145  0.1862166   0.47619453 ... -0.0946024   0.59739417\n",
      "     0.07075642]]\n",
      "\n",
      "  [[ 0.10740133 -0.0761627   0.10787938 ... -0.26927486  0.02043007\n",
      "     0.00636149]\n",
      "   [ 0.06979701  0.1751449   0.10183374 ...  0.10515207 -0.1346812\n",
      "    -0.13173579]\n",
      "   [ 0.3852196   0.02225341 -0.16102184 ...  0.26361927 -0.21206959\n",
      "    -0.01216436]\n",
      "   ...\n",
      "   [ 0.2937747  -0.26133886 -0.1029091  ...  0.2007968  -0.08044332\n",
      "    -0.3739228 ]\n",
      "   [ 0.16024429 -0.27667677  0.1639067  ...  0.23582946 -0.18032165\n",
      "    -0.01438955]\n",
      "   [ 0.40954328 -0.08972719 -0.1349788  ... -0.03480539 -0.11391028\n",
      "    -0.05793208]]\n",
      "\n",
      "  [[-0.22620611  0.27757296 -0.29652902 ... -0.1224735  -0.21306011\n",
      "     0.137406  ]\n",
      "   [ 0.28157267  0.12164824 -0.03983056 ... -0.06731698 -0.21906379\n",
      "     0.00965205]\n",
      "   [ 0.03959324  0.10477707 -0.15544528 ... -0.16678773  0.40910885\n",
      "     0.00586155]\n",
      "   ...\n",
      "   [-0.22362517  0.2812439  -0.08381356 ... -0.07430895 -0.35786676\n",
      "    -0.27814558]\n",
      "   [-0.13850327  0.13935792  0.2999352  ... -0.09524747 -0.10935163\n",
      "    -0.19867052]\n",
      "   [-0.14116378  0.16224307 -0.2008997  ... -0.03526957 -0.01215724\n",
      "     0.18305899]]\n",
      "\n",
      "  [[ 0.26009876 -0.45799565  0.03924971 ...  0.04719594  0.02034301\n",
      "    -0.29702982]\n",
      "   [-0.03105316 -0.08201425 -0.11919228 ... -0.25178465 -0.36906093\n",
      "    -0.06341221]\n",
      "   [-0.03609798 -0.00720212 -0.47269565 ...  0.27088472 -0.09664336\n",
      "    -0.33990276]\n",
      "   ...\n",
      "   [ 0.21301831  0.13123901  0.13391724 ...  0.06874567  0.02704295\n",
      "    -0.03098488]\n",
      "   [ 0.26378268 -0.1867524  -0.03449621 ...  0.08077279  0.14847207\n",
      "    -0.13088313]\n",
      "   [-0.24189787 -0.06004621 -0.51820797 ...  0.04345676  0.08746421\n",
      "    -0.12316742]]]\n",
      "\n",
      "\n",
      " [[[-0.03705761  0.11348107 -0.17373872 ...  0.10628682 -0.03285808\n",
      "    -0.38749787]\n",
      "   [ 0.14184715  0.14046298 -0.00179963 ... -0.04317749 -0.2704013\n",
      "    -0.16419676]\n",
      "   [ 0.09018705 -0.11167225  0.09405103 ...  0.14643325 -0.27127138\n",
      "    -0.17013757]\n",
      "   ...\n",
      "   [-0.1612485  -0.15851358 -0.253544   ...  0.14236902 -0.4599287\n",
      "     0.01207187]\n",
      "   [-0.04512225 -0.33302724 -0.29949772 ...  0.15013772 -0.11688478\n",
      "    -0.28472704]\n",
      "   [ 0.12815987  0.11049244  0.03132318 ... -0.04458154 -0.40826407\n",
      "    -0.23064926]]\n",
      "\n",
      "  [[ 0.0178639  -0.03497809 -0.7276545  ... -0.6340287  -0.05971379\n",
      "    -0.12357029]\n",
      "   [ 0.04318924  0.4286188  -0.40814522 ... -0.25420228  0.06753185\n",
      "    -0.2098928 ]\n",
      "   [ 0.25620177  0.32110956 -0.24344178 ... -0.4959748   0.21915032\n",
      "    -0.48360378]\n",
      "   ...\n",
      "   [ 0.12756702  0.47231865 -0.19846477 ... -0.47778493  0.2184415\n",
      "    -0.11947561]\n",
      "   [ 0.41770408  0.3751961  -0.5471413  ... -0.6478446   0.18719244\n",
      "    -0.27870905]\n",
      "   [-0.18180035  0.19968796 -0.50390995 ... -0.4068999  -0.12254478\n",
      "    -0.32306302]]\n",
      "\n",
      "  [[ 0.14297116 -0.11669623 -0.3891266  ...  0.13235587 -0.09408862\n",
      "     0.14167489]\n",
      "   [ 0.2784433  -0.36153808 -0.03864206 ...  0.38560846 -0.3026141\n",
      "     0.08807313]\n",
      "   [ 0.28650364 -0.13216527  0.11180769 ...  0.44940025 -0.13067015\n",
      "     0.22138941]\n",
      "   ...\n",
      "   [ 0.06338979 -0.17053913  0.10070613 ...  0.30563653 -0.35203356\n",
      "    -0.19041552]\n",
      "   [-0.02375947 -0.5286788  -0.7076983  ...  0.21743804 -0.23322797\n",
      "     0.38845444]\n",
      "   [ 0.62525535 -0.04904363  0.01779276 ... -0.00188105 -0.09187597\n",
      "    -0.1939112 ]]\n",
      "\n",
      "  [[ 0.04140858  0.37263787 -0.22993205 ...  0.25997207  0.37285167\n",
      "     0.1809734 ]\n",
      "   [ 0.10704408 -0.14986128 -0.2516876  ... -0.19395557  0.62285936\n",
      "    -0.11298352]\n",
      "   [ 0.20629627 -0.28365016 -0.49728718 ... -0.5590802   0.19374983\n",
      "     0.53784066]\n",
      "   ...\n",
      "   [-0.05047517 -0.13747996 -0.3180963  ...  0.03508228  0.46122077\n",
      "     0.1514041 ]\n",
      "   [-0.11991464  0.30295327 -0.32313073 ... -0.10996009  0.40743098\n",
      "    -0.20285542]\n",
      "   [ 0.259757    0.29597485 -0.02053223 ... -0.49228474  0.6225653\n",
      "     0.0805489 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.14563513 -0.06332403  0.23350938 ... -0.23352231 -0.3076247\n",
      "     0.09319334]\n",
      "   [-0.03656038  0.28196207 -0.04390271 ...  0.4510202  -0.03346662\n",
      "     0.3036393 ]\n",
      "   [-0.02602092  0.04136287  0.0237106  ... -0.09014406 -0.2039742\n",
      "     0.21237147]\n",
      "   ...\n",
      "   [-0.02509955  0.11600111 -0.4738512  ... -0.27103457 -0.47056773\n",
      "    -0.04512898]\n",
      "   [ 0.1554752   0.1953783  -0.00809411 ...  0.27174252 -0.40579927\n",
      "    -0.09394904]\n",
      "   [-0.20704755 -0.13873415  0.15187408 ... -0.07213552 -0.06418033\n",
      "     0.28432682]]\n",
      "\n",
      "  [[-0.38262784  0.04096893 -0.00847219 ... -0.08240227  0.31943458\n",
      "    -0.06802164]\n",
      "   [-0.21139489 -0.10379335  0.05818385 ... -0.40634048  0.14229695\n",
      "    -0.09289598]\n",
      "   [-0.0611139  -0.21559213  0.1264196  ...  0.11056933 -0.17552882\n",
      "     0.03162137]\n",
      "   ...\n",
      "   [ 0.00679299  0.17037898 -0.08629306 ...  0.11125175 -0.15894847\n",
      "     0.01742603]\n",
      "   [-0.2542185   0.06769227  0.23874223 ... -0.19813061  0.35841402\n",
      "    -0.03542224]\n",
      "   [ 0.05437262  0.16802077  0.07829615 ... -0.20693386  0.27431816\n",
      "     0.2019158 ]]\n",
      "\n",
      "  [[ 0.29628885  0.5189063  -0.45802957 ... -0.437922    0.06621704\n",
      "    -0.0811016 ]\n",
      "   [ 0.4152392   0.82463545 -0.94496167 ... -0.5407437   0.37139356\n",
      "    -0.16797504]\n",
      "   [ 0.14938633  0.50551325 -0.5007383  ... -0.5070133   0.27393273\n",
      "    -0.02926662]\n",
      "   ...\n",
      "   [-0.10496388  0.5157686  -0.40157694 ... -0.03435274  0.07236388\n",
      "    -0.15641718]\n",
      "   [ 0.18798603  0.03368266 -0.19220112 ... -0.2254245   0.04096727\n",
      "     0.04539606]\n",
      "   [-0.46545506  0.665116   -0.63786775 ... -0.2362477   0.03608533\n",
      "    -0.53730905]]\n",
      "\n",
      "  [[ 0.18252097 -0.19724882 -0.01650158 ...  0.14741814 -0.36456388\n",
      "     0.02731934]\n",
      "   [-0.25458485 -0.09387181  0.00524394 ... -0.17161517 -0.24342626\n",
      "     0.22719757]\n",
      "   [ 0.0479121   0.01831813  0.01159904 ... -0.04859958 -0.11864922\n",
      "    -0.10345482]\n",
      "   ...\n",
      "   [-0.08252799  0.0552395   0.04099155 ... -0.05504875 -0.0941274\n",
      "     0.12012619]\n",
      "   [-0.21546958 -0.05903222  0.03721115 ... -0.15713331 -0.39074937\n",
      "     0.1207692 ]\n",
      "   [ 0.07173456 -0.1569572   0.13630813 ...  0.06952256  0.03747243\n",
      "     0.21448743]]]\n",
      "\n",
      "\n",
      " [[[ 0.21257047  0.20588169 -0.1047077  ... -0.20274721  0.25157824\n",
      "    -0.04754284]\n",
      "   [ 0.16305293 -0.00569858  0.2799334  ... -0.08749574  0.21010423\n",
      "     0.1794184 ]\n",
      "   [ 0.17856443 -0.02967422  0.20354411 ... -0.2338515   0.28119567\n",
      "     0.18414003]\n",
      "   ...\n",
      "   [ 0.04044912  0.19498052  0.18011189 ... -0.28822887  0.19622794\n",
      "     0.4580667 ]\n",
      "   [-0.04991938  0.2803171   0.11875636 ... -0.21057636  0.14611824\n",
      "     0.16178878]\n",
      "   [ 0.01916487 -0.07081258  0.28250116 ...  0.01992564  0.06541944\n",
      "    -0.01863578]]\n",
      "\n",
      "  [[-0.36508754  0.11317667 -0.3816568  ... -0.1811077   0.01588879\n",
      "     0.18167241]\n",
      "   [-0.00184634 -0.365051    0.00966601 ...  0.06661446  0.21617393\n",
      "     0.2595449 ]\n",
      "   [-0.21777613  0.20100336 -0.02494743 ... -0.8210012   0.12795055\n",
      "    -0.00870923]\n",
      "   ...\n",
      "   [-0.07454875 -0.23681901 -0.317718   ... -0.0513797  -0.06334764\n",
      "     0.21159087]\n",
      "   [-0.19502999 -0.17292552  0.33030364 ... -0.1914974   0.11383189\n",
      "     0.04371126]\n",
      "   [ 0.08547684 -0.25434223 -0.26621947 ... -0.0800024  -0.14445412\n",
      "    -0.02975217]]\n",
      "\n",
      "  [[ 0.19444829  0.3110039   0.16362987 ... -0.15552247 -0.2653235\n",
      "     0.08347553]\n",
      "   [-0.23732425  0.04208807 -0.09677974 ... -1.0642904   0.18640974\n",
      "     0.23879975]\n",
      "   [-0.3279152  -0.04358526  0.01348459 ... -0.38849977 -0.20497182\n",
      "     0.20275974]\n",
      "   ...\n",
      "   [ 0.34758136 -0.36433247 -0.02079016 ... -0.45232227 -0.01747965\n",
      "     0.12569876]\n",
      "   [-0.04046137 -0.0922371  -0.03762444 ...  0.5339908  -0.48596954\n",
      "     0.2340721 ]\n",
      "   [ 0.0425434   0.36698446 -0.26966923 ... -0.05857724 -0.13910893\n",
      "     0.10977802]]\n",
      "\n",
      "  [[ 0.23715964  0.77014375 -1.0724458  ...  0.19232114 -0.10096872\n",
      "     0.25745368]\n",
      "   [ 0.39071724 -0.04520893 -0.36850512 ...  0.08293057  0.66795266\n",
      "     0.24847005]\n",
      "   [ 0.19391663  0.04181001 -0.47069746 ...  0.01763603  0.5523631\n",
      "     0.73939073]\n",
      "   ...\n",
      "   [ 0.36800736 -0.12559259 -0.20610274 ...  0.35560605  0.382815\n",
      "     0.37185517]\n",
      "   [ 0.20155895 -0.04791061  0.21610832 ... -0.01977566  0.15126769\n",
      "     0.29014167]\n",
      "   [ 0.36097336 -0.06041257 -0.03605957 ...  0.37958357  0.49396884\n",
      "     0.6587756 ]]]\n",
      "\n",
      "\n",
      " [[[-0.03944623 -0.09270839 -0.2827702  ... -0.5013176  -0.34003285\n",
      "     0.08783882]\n",
      "   [-0.01836099  0.22141713 -0.12285709 ... -0.11316159 -0.19540262\n",
      "    -0.075555  ]\n",
      "   [-0.08136185  0.0818267  -0.03232708 ...  0.22752517 -0.02753929\n",
      "     0.16742828]\n",
      "   ...\n",
      "   [-0.08025198  0.17354025 -0.28671068 ... -0.5011214  -0.5539067\n",
      "     0.1590337 ]\n",
      "   [ 0.1855709   0.49585265 -0.3199911  ...  0.03760228 -0.28074133\n",
      "     0.07458057]\n",
      "   [-0.14030434  0.01479576 -0.02436244 ...  0.03052574 -0.17351642\n",
      "     0.13827845]]\n",
      "\n",
      "  [[ 0.15044574  0.5073227  -0.04507583 ... -0.1453506  -0.21397063\n",
      "     0.5861069 ]\n",
      "   [ 0.10519928 -0.09821839 -0.16369982 ... -0.32141134  0.11086629\n",
      "     0.30284795]\n",
      "   [-0.55257016  0.08065931 -0.16362391 ... -0.36435738 -0.14193735\n",
      "     0.8359376 ]\n",
      "   ...\n",
      "   [-0.16362028  0.05210568 -0.23600018 ... -0.11889827 -0.03174893\n",
      "     0.5933284 ]\n",
      "   [ 0.2721612   0.07961429 -0.16836315 ... -0.10031869 -0.32925206\n",
      "     0.5922274 ]\n",
      "   [-0.22661932 -0.08990914 -0.15871793 ... -0.6817572  -0.07050334\n",
      "     0.7784727 ]]\n",
      "\n",
      "  [[-0.15551242  0.12830205  0.07392835 ...  0.20080149 -0.1638156\n",
      "    -0.18891275]\n",
      "   [ 0.0958844  -0.19474916  0.09135441 ...  0.3963323  -0.40878403\n",
      "    -0.17152378]\n",
      "   [ 0.29535502  0.11852983  0.29428893 ...  0.18112394 -0.333265\n",
      "    -0.1365545 ]\n",
      "   ...\n",
      "   [ 0.01395547  0.14196956 -0.15585427 ... -0.11044158  0.11590144\n",
      "     0.016885  ]\n",
      "   [ 0.5125679   0.3784202   0.12875517 ...  0.6397226  -0.40516824\n",
      "     0.04770478]\n",
      "   [-0.05674282 -0.2640404  -0.1859652  ...  0.22686628  0.0615918\n",
      "     0.22722054]]\n",
      "\n",
      "  [[ 0.16497242  0.47550365  0.28715158 ... -0.19473521  0.34651792\n",
      "    -0.06638709]\n",
      "   [-0.03719909  0.01087137  0.16930977 ... -0.4065987   0.6867982\n",
      "     0.04008253]\n",
      "   [-0.47357875  0.10848764  0.16795497 ... -0.15226516 -0.01318972\n",
      "     0.04125431]\n",
      "   ...\n",
      "   [-0.40305954 -0.13343431 -0.03290138 ... -0.12396973  0.0683804\n",
      "     0.154258  ]\n",
      "   [-0.04901418  0.931374   -0.12759641 ... -0.35517365  0.15429582\n",
      "     0.20200825]\n",
      "   [-0.0246571   0.67712486  0.17636399 ... -0.3508859   0.16620333\n",
      "     0.35026982]]]], shape=(64, 4, 40, 32), dtype=float32)\n",
      "(64, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "# 실제 데이터 입력 - (N, T, D) T=40(문장 1개 당 단어의 길이)\n",
    "x = tf.constant(np.random.randn(64,40,128))\n",
    "# inputs = { 'query':x, 'key':x, 'value':x, 'mask':None } # 가공 전 query=key\n",
    "# mha = MultiHeadAttention(128,4)\n",
    "# mha(inputs) # 만들어진 객체를 call -> call()호출\n",
    "\n",
    "# 위의 코드를 합쳐서 쓰면\n",
    "outputs = MultiHeadAttention(128,4)({'query':x, 'key':x, 'value':x, 'mask':None})\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 1, 1, 5)\n",
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 문자는 계산에 사용되지 않는다\n",
    "x = tf.constant([[1, 21, 777, 0, 0]])\n",
    "print(x.shape)\n",
    "# mask = tf.math.equal(x, 0)\n",
    "mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "print(mask.shape)\n",
    "mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 1, 1, 5)\n",
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 1.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 21, 777, 0, 0],\n",
    "                 [23, 34, 31, 12, 0]])\n",
    "print(x.shape)\n",
    "mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "print(mask.shape)\n",
    "mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):  # (2,5)\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # (2,5)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "#     print(mask) #  [[0, 0, 0, 1, 1],\n",
    "                #   [1, 1, 0, 0, 0]]  (2,5)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#  0,0 5자리를 맞추기 위해 패딩\n",
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))  # (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 0. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0],\n",
    "                                       [0, 0, 777, 23, 25]])))  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.0320586  0.08714432 0.2368828  0.6439142  0.        ], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 패딩에 0이 아닌 1e-9를 넣는 이유\n",
    "# logits = tf.constant([1.,2.,3.,4.,0.]) # 0인 경우, 0.01165623\n",
    "logits = tf.constant([1.,2.,3.,4.,-1000000000]) # 아주 작은 수인 경우, 0.\n",
    "attention_weights = tf.nn.softmax(logits, axis = -1)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "logits= tf.Tensor(\n",
      "[[[[-0.8604314  -0.6006049   1.6691302   1.5278038 ]\n",
      "   [-0.0263841   0.7212323   0.9024451   0.7755365 ]\n",
      "   [-1.0307772   0.3297551   1.813923    0.9625724 ]\n",
      "   [-0.9952053   1.453032    0.3544928   0.7198589 ]]\n",
      "\n",
      "  [[-2.2006116  -1.3655452   0.6784962  -1.1276982 ]\n",
      "   [-2.889778   -1.3557283  -1.9291644   0.7287981 ]\n",
      "   [-0.94129384 -1.1965059  -0.34277287 -0.00456636]\n",
      "   [ 0.02369308  1.8595539  -0.17542033 -1.1133066 ]]\n",
      "\n",
      "  [[ 1.0326271  -0.6045838   0.77593446  1.101066  ]\n",
      "   [ 0.03653472 -1.0523369   1.0183653   1.9052736 ]\n",
      "   [ 0.00842478  1.4442008   0.96704733  0.8676384 ]\n",
      "   [ 1.401681   -2.3256142  -1.9649222  -0.6158382 ]]\n",
      "\n",
      "  [[ 0.48451564  0.1821836   1.7385336   0.4127306 ]\n",
      "   [ 0.00674114  1.7280456  -0.8368726  -0.8338761 ]\n",
      "   [ 0.18892704  0.30502307  1.2280482   0.4916521 ]\n",
      "   [ 0.20232473 -0.6410892  -0.11899135  0.4341609 ]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "logits= tf.Tensor(\n",
      "[[[[-8.60431373e-01 -6.00604892e-01  1.66913021e+00 -1.00000000e+09]\n",
      "   [-2.63840966e-02  7.21232295e-01  9.02445078e-01 -1.00000000e+09]\n",
      "   [-1.03077722e+00  3.29755098e-01  1.81392300e+00 -1.00000000e+09]\n",
      "   [-9.95205283e-01  1.45303202e+00  3.54492813e-01 -1.00000000e+09]]\n",
      "\n",
      "  [[-2.20061159e+00 -1.36554515e+00  6.78496182e-01 -1.00000000e+09]\n",
      "   [-2.88977790e+00 -1.35572827e+00 -1.92916441e+00 -1.00000000e+09]\n",
      "   [-9.41293836e-01 -1.19650590e+00 -3.42772871e-01 -1.00000000e+09]\n",
      "   [ 2.36930829e-02  1.85955393e+00 -1.75420329e-01 -1.00000000e+09]]\n",
      "\n",
      "  [[ 1.03262711e+00 -6.04583800e-01  7.75934458e-01 -1.00000000e+09]\n",
      "   [ 3.65347229e-02 -1.05233693e+00  1.01836526e+00 -1.00000000e+09]\n",
      "   [ 8.42477567e-03  1.44420075e+00  9.67047334e-01 -1.00000000e+09]\n",
      "   [ 1.40168095e+00 -2.32561421e+00 -1.96492219e+00 -1.00000000e+09]]\n",
      "\n",
      "  [[ 4.84515637e-01  1.82183594e-01  1.73853362e+00 -1.00000000e+09]\n",
      "   [ 6.74113585e-03  1.72804558e+00 -8.36872578e-01 -1.00000000e+09]\n",
      "   [ 1.88927040e-01  3.05023074e-01  1.22804821e+00 -1.00000000e+09]\n",
      "   [ 2.02324733e-01 -6.41089201e-01 -1.18991345e-01 -1.00000000e+09]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "attention_weights= tf.Tensor(\n",
      "[[[[0.06736408 0.08735134 0.84528464 0.        ]\n",
      "   [0.1771949  0.3742285  0.44857657 0.        ]\n",
      "   [0.04525978 0.17643476 0.7783055  0.        ]\n",
      "   [0.06088576 0.7043228  0.23479143 0.        ]]\n",
      "\n",
      "  [[0.04738584 0.10922279 0.84339136 0.        ]\n",
      "   [0.12120895 0.5620358  0.31675524 0.        ]\n",
      "   [0.27822772 0.21555755 0.50621474 0.        ]\n",
      "   [0.1236096  0.77509767 0.10129274 0.        ]]\n",
      "\n",
      "  [[0.5080971  0.09883599 0.39306694 0.        ]\n",
      "   [0.24962965 0.08402437 0.66634595 0.        ]\n",
      "   [0.12802447 0.53807473 0.3339008  0.        ]\n",
      "   [0.9446755  0.02272683 0.03259759 0.        ]]\n",
      "\n",
      "  [[0.19071276 0.14095439 0.6683329  0.        ]\n",
      "   [0.14241014 0.7963316  0.06125819 0.        ]\n",
      "   [0.20202693 0.2268972  0.5710759  0.        ]\n",
      "   [0.46394387 0.19960684 0.33644933 0.        ]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "value.shape= (1, 4, 4, 32)\n",
      "value= tf.Tensor(\n",
      "[[[[ 0.6929017   0.84151244  0.16982676 -1.3616166  -0.8122109\n",
      "     0.16310625 -0.00719828  0.5499877  -0.43165326  0.17784153\n",
      "     1.1478311  -0.9945191   0.02196929  0.5337115   0.41314954\n",
      "    -0.70382786 -0.43175447 -0.9285824  -0.5314029  -0.2103656\n",
      "    -0.6793962   0.06768858  0.2998864  -0.83838433 -0.2527027\n",
      "     0.07920114  0.24193348  0.32143953 -0.5873576  -0.77613056\n",
      "    -0.74865144  2.122211  ]\n",
      "   [-0.18742158  1.3128649   0.1357083  -0.24601981  0.13060455\n",
      "    -0.52304393  0.31703374  0.06658389 -1.3645817  -1.454895\n",
      "     2.2838197  -1.655332    0.60453     3.0695517   1.1552268\n",
      "    -0.08773683 -0.879369   -0.13718152 -0.05925866  1.6893015\n",
      "    -0.08535378  1.6868798  -1.5585467  -0.2696134   1.0837452\n",
      "    -0.07035249  1.1749666   1.7522724   0.9716944  -0.33014035\n",
      "    -0.5565819  -0.01701639]\n",
      "   [ 0.4781825   0.9836182   0.57795364 -0.3727163   1.2024235\n",
      "     0.88466287  1.0492499   0.39667293 -0.99912876  0.20389646\n",
      "     0.48863527 -1.8988069  -0.31354827  1.0350872   1.1033762\n",
      "    -0.08254116  2.2338564  -1.33207     1.3099595  -0.9596846\n",
      "     0.37477675 -2.1896744   1.4554033  -1.7584809   1.1404179\n",
      "     1.6549898   1.8919042   0.16686061  0.5375518   0.1457297\n",
      "    -0.9297774  -0.9107687 ]\n",
      "   [ 0.84440666 -0.20016684 -0.20457567  1.3457085  -0.22364065\n",
      "     0.7039294   0.2282396  -0.8046354   0.7275525   0.04498529\n",
      "     1.083688    0.10982733 -0.73913175 -0.17657936  0.0966889\n",
      "    -1.5445199   0.06295949 -0.0768404  -0.8234198   0.49038982\n",
      "     1.4478686   0.57785577  1.297774    0.79143155  0.8701283\n",
      "     0.19800024  0.31462207 -1.2561865  -0.99069     0.23392464\n",
      "     1.222645    0.9506691 ]]\n",
      "\n",
      "  [[-0.00461036  1.097778    0.45505065 -1.8616068   0.9180941\n",
      "    -0.11915725  0.68462914 -0.21088018  0.24606252 -0.7486939\n",
      "    -0.74960697  0.3093326   1.74093    -0.38081285  0.1022779\n",
      "    -0.13356867  0.31192234 -0.53119767  0.47954866  1.4534911\n",
      "     2.5914638  -0.12135267 -0.21397856  0.44692728  0.36933064\n",
      "    -0.7681326   0.7026472  -0.63585985 -1.5436136  -0.5864463\n",
      "     1.3992809  -1.9936379 ]\n",
      "   [ 0.15154499 -0.25276694  0.98682064 -0.65061456  0.67891985\n",
      "    -0.3588489  -0.755489   -0.06888212  0.29407156  0.02254225\n",
      "     0.75122404 -1.1253558  -0.06245837  0.12832226 -0.12049038\n",
      "     0.5718786  -1.0512588  -2.4262428  -0.5894993  -0.50959396\n",
      "     1.7645812  -1.1753479   1.1223601  -1.0265087  -0.6682821\n",
      "     0.04660397 -1.0247475  -0.40520975 -0.17922455 -1.3043566\n",
      "     1.5084467  -1.6156073 ]\n",
      "   [ 0.54484373  0.2967408  -0.5651999   0.46970245  1.6864498\n",
      "    -0.10652902  1.1404448   1.7624733  -0.53272504  1.6157068\n",
      "    -1.19576     0.26895046 -1.89755     1.0892494   0.57865745\n",
      "     0.9182262  -1.2423697  -0.21903317 -0.28055388 -0.1528297\n",
      "     0.8209104   0.9089796  -2.924171   -0.7276985  -0.07501773\n",
      "    -0.6013498   1.6924168   1.6012118   1.6567563   0.5831637\n",
      "    -2.0522223  -0.3444487 ]\n",
      "   [-1.368225    0.9131706  -0.50630957  1.8767276   0.28755838\n",
      "    -0.05382303 -0.38149035 -0.48191288  0.32929304  0.93564475\n",
      "     0.23546748  0.71768314  0.38711137  1.4178575  -0.50107765\n",
      "     1.137791   -0.38389823 -0.42967197  0.23530667  0.93993956\n",
      "    -0.41184     0.5506017  -1.7915101   0.54036593  0.5584202\n",
      "    -0.23371458 -1.15009    -1.6475087   0.79453707 -0.08751129\n",
      "    -0.31833625 -0.37670574]]\n",
      "\n",
      "  [[-0.7813025   0.8595812  -0.28867754  1.3589935   0.35474762\n",
      "     0.08822751 -0.35775194  0.04477616  0.21250601 -0.59038776\n",
      "    -0.5806624   0.66133153 -0.7559453   0.91481507  1.028107\n",
      "    -1.081851   -0.03247783 -0.66423553 -1.5350724  -1.4368012\n",
      "    -1.8113443   0.2277264   1.0059471   0.78914446 -0.5355499\n",
      "     0.7137214   0.76517427  0.65144515 -1.1476163  -1.0414941\n",
      "    -0.24702767  0.2519837 ]\n",
      "   [-1.615907   -0.6719727   0.08010446 -1.6845872   1.3361232\n",
      "    -0.17555238  0.46198598 -1.2239991  -0.619358   -0.9690622\n",
      "    -0.607336    0.40886137  1.2874004  -0.15832947 -1.1519064\n",
      "    -0.20063844 -0.8396594   0.93527997  0.50429964 -1.4235116\n",
      "     1.901206    0.50299895  0.05996336  0.8236754   1.9535656\n",
      "    -0.06065527  0.20296088  0.97810906 -0.5521029  -0.8302031\n",
      "     0.95150656  2.137124  ]\n",
      "   [ 0.93705547  1.5908006   0.99648666  1.15481    -2.5393288\n",
      "     1.3136255   0.59926474 -0.56171316 -0.10460531 -0.7296697\n",
      "    -0.41785413  1.3420337  -1.58873     1.0476577  -0.315065\n",
      "     0.472009   -0.8758886  -1.0572723  -0.46216825 -0.24055132\n",
      "     1.3138627  -2.6133897  -0.5705206  -0.23313735  1.5128645\n",
      "    -1.8304667  -0.3151759  -0.9817543   0.3446578   0.10382229\n",
      "    -1.093094   -0.78770715]\n",
      "   [-1.562696    0.51088893 -0.24239244  0.09232336  1.8296444\n",
      "     1.7872252  -0.51069045 -0.6715931   1.3888102   0.15227029\n",
      "     1.2300237  -1.8719397  -0.6723758  -0.47307116 -0.16321611\n",
      "     0.35959098 -0.51161575 -0.20552994  0.03409452 -0.9090035\n",
      "    -1.5181171  -0.04820632 -1.0149907   0.00296249  0.8978849\n",
      "     0.46715438 -0.8503284  -1.4471501   0.5772028   0.06730936\n",
      "     1.062945    0.73073727]]\n",
      "\n",
      "  [[ 0.06148033 -0.6521844   0.68326056  0.8708514  -0.42727157\n",
      "     1.0822606  -0.3692681  -0.8526749   0.16102579 -1.4677444\n",
      "    -0.07652509  0.54353637 -1.7236838  -0.26800045 -1.9489483\n",
      "    -0.65472215 -0.5672262   0.96294993  0.8896529   0.9700915\n",
      "    -0.9840099   0.50529903 -0.4777857   0.89846146 -0.8354982\n",
      "    -1.1858703  -0.439987    0.17287816 -0.06259549  0.39724863\n",
      "     0.01917542  1.0664958 ]\n",
      "   [ 1.3315669  -0.7734326  -0.65154773 -1.147272   -2.1344411\n",
      "     1.4747889   1.3876443  -0.40537378 -0.01076789  0.4021824\n",
      "     0.43080267  1.2040141   0.71811205 -0.01648512  0.20019919\n",
      "    -0.56203    -1.9081931  -0.09646109 -0.2819886   0.41729823\n",
      "     1.1989889   0.2272285   0.08266357  2.2002902   3.2852547\n",
      "     0.3303006  -0.9936818  -0.61230135 -0.5968148   1.8225745\n",
      "    -0.21382189  0.61106664]\n",
      "   [ 0.7452372   0.1761743   0.25268015  2.3393915   0.6384832\n",
      "    -0.4958735   1.2043575  -0.933868   -0.72575676  0.5478477\n",
      "    -0.26350117  0.30736598 -2.0799034  -1.271807   -0.8519783\n",
      "     1.0795159   1.1755286   0.3475569   1.2045933  -0.09601853\n",
      "     0.04570894  0.2678175   0.20098548 -1.5001559  -1.0950783\n",
      "     0.06147702  1.1495291  -0.19371422 -0.12002806 -0.79634887\n",
      "    -0.6028276  -0.9197367 ]\n",
      "   [ 0.50980383  0.05338639 -0.87880605 -0.392312    0.458688\n",
      "    -0.5381126  -0.9241304  -1.3578006   2.0658774   1.0217558\n",
      "    -1.2992189  -0.7660189  -0.41818577  0.06490172 -1.8859433\n",
      "    -1.006445    1.7153312   1.0940887  -0.9961477  -0.5811316\n",
      "    -0.06139963  0.32961953 -0.7457409   1.5226861   0.10466753\n",
      "    -1.6881473   0.723151   -0.6969641   0.9958852   1.3428553\n",
      "    -0.5608857  -1.1938682 ]]]], shape=(1, 4, 4, 32), dtype=float32)\n",
      "output = tf.Tensor(\n",
      "[[[[ 0.43450546  1.0028056   0.51182985 -0.42826557  0.97308475\n",
      "     0.71309084  0.9141232   0.37816715 -0.99282414  0.05724366\n",
      "     0.6898532  -1.8166226  -0.21075109  1.1790258   1.061409\n",
      "    -0.12484742  1.7823457  -1.2005144   1.0663149  -0.67781496\n",
      "     0.26357037 -1.6989871   1.1142905  -1.566445    1.0416212\n",
      "     1.3981274   1.7181301   0.3157615   0.49969628  0.04206156\n",
      "    -0.8849769  -0.6283844 ]\n",
      "   [ 0.2671416   1.0816512   0.3401348  -0.50053096  0.4443353\n",
      "     0.23000267  0.5880365   0.3003108  -1.0353379  -0.42148742\n",
      "     1.2772505  -1.6474564   0.08947478  1.7076006   1.0004754\n",
      "    -0.19457436  0.596466   -0.81341267  0.471279    0.16441703\n",
      "     0.0157887  -0.33896405  0.12274551 -1.0382679   0.8723555\n",
      "     0.7300958   1.3312393   0.7875575   0.5006921  -0.19570337\n",
      "    -0.75802237 -0.03887254]\n",
      "   [ 0.37046495  1.0352771   0.48145446 -0.39512005  0.9221355\n",
      "     0.603637    0.8722469   0.34537274 -1.0379236  -0.08995125\n",
      "     0.83520323 -1.8149216  -0.13638191  1.3713453   1.0812849\n",
      "    -0.11157715  1.5639303  -1.1029884   0.9850422  -0.4583974\n",
      "     0.2458821  -1.4035478   0.8713393  -1.4541496   1.0673666\n",
      "     1.2792596   1.6907343   0.45357853  0.5632365   0.0200465\n",
      "    -0.855735   -0.6158077 ]\n",
      "   [ 0.02245571  1.206862    0.24162105 -0.34369102  0.3248544\n",
      "    -0.15074967  0.46921068  0.17351837 -1.2219744  -0.9660146\n",
      "     1.7931602  -1.6722636   0.35350344  2.4374804   1.0978708\n",
      "    -0.12402811 -0.12115699 -0.46591616  0.23347516  0.9516796\n",
      "    -0.0134878   0.6781124  -0.737745   -0.65381676  1.0156809\n",
      "     0.3438488   1.286489    1.2929139   0.7748374  -0.2455646\n",
      "    -0.6558993  -0.09661327]]\n",
      "\n",
      "  [[ 0.4758502   0.27467984 -0.34733847  0.23686725  1.5399953\n",
      "    -0.1346865   0.91176635  1.4689386  -0.4055165   1.3296578\n",
      "    -0.96196365  0.11857397 -1.5247037   0.9146341   0.47972092\n",
      "     0.8305569  -1.1478446  -0.47490296 -0.27827966 -0.11567964\n",
      "     1.0078799   0.63250035 -2.3537729  -0.7046747  -0.1187599\n",
      "    -0.5384816   1.3487395   1.2760593   1.304573    0.32158047\n",
      "    -1.4997636  -0.5614364 ]\n",
      "   [ 0.257197    0.08499065  0.43075475 -0.4425314   1.0270503\n",
      "    -0.24987248  0.01961318  0.49399787  0.02636029  0.43370473\n",
      "    -0.04740751 -0.5098049  -0.42514646  0.37098923  0.12796986\n",
      "     0.59607947 -0.94656444 -1.4974011  -0.36206105 -0.15864354\n",
      "     1.5658941  -0.3873726  -0.32137603 -0.7532654  -0.35459453\n",
      "    -0.25739214  0.04530421  0.20237792  0.23695582 -0.6194575\n",
      "     0.36735433 -1.2587818 ]\n",
      "   [ 0.30719185  0.40116102  0.05321184 -0.42042518  1.2554913\n",
      "    -0.164432    0.6049414   0.8186692  -0.13782251  0.61444634\n",
      "    -0.65194076 -0.02036734 -0.48965618  0.47310224  0.29540887\n",
      "     0.5509299  -0.7687272  -0.7816667  -0.1356678   0.21719003\n",
      "     1.5169427   0.17302006 -1.29786    -0.46529582 -0.07927031\n",
      "    -0.5080821   0.83133024  0.5462972   0.37056515 -0.14912346\n",
      "    -0.3243894  -1.0773067 ]\n",
      "   [ 0.172081   -0.03016547  0.7638804  -0.68682486  0.8105396\n",
      "    -0.30366257 -0.3854322   0.09906857  0.2043887   0.08858605\n",
      "     0.3684916  -0.8067815  -0.02542372  0.16272321 -0.02213548\n",
      "     0.519761   -0.9021146  -1.9684229  -0.42606077 -0.23080015\n",
      "     1.7712048  -0.83393675  0.54729164 -0.8141105  -0.47992986\n",
      "    -0.1197383  -0.53599596 -0.2304844  -0.1619046  -1.024424\n",
      "     1.1342828  -1.5335764 ]]\n",
      "\n",
      "  [[-0.18836176  0.9956268   0.25292695  0.9779205  -0.6858229\n",
      "     0.54382     0.09943928 -0.3190154   0.00564194 -0.6825616\n",
      "    -0.51930416  0.90393996 -0.88132936  0.86096585  0.28468674\n",
      "    -0.3839845  -0.4437733  -0.6606356  -0.91178596 -0.9652815\n",
      "    -0.21599525 -0.8618155   0.29279262  0.3907322   0.5156282\n",
      "    -0.36285108  0.28495747  0.04177463 -0.5021945  -0.57042503\n",
      "    -0.46113005  0.02963531]\n",
      "   [ 0.29359126  1.2181385   0.5986731   0.96720165 -1.491249\n",
      "     0.8826026   0.34883022 -0.4659636  -0.06869669 -0.71501553\n",
      "    -0.47441697  1.093701   -1.1391772   0.9131639  -0.05008447\n",
      "     0.02760068 -0.6623041  -0.7917357  -0.6487901  -0.6385683\n",
      "     0.5830695  -1.6423103  -0.12401149  0.11085252  1.0385491\n",
      "    -1.0466546  -0.00195234 -0.409383   -0.10320784 -0.26056352\n",
      "    -0.71009445 -0.28241238]\n",
      "   [-0.656621    0.2796455   0.3388721  -0.34685743 -0.08353347\n",
      "     0.35545558  0.40287697 -0.84042704 -0.3409827  -0.84064925\n",
      "    -0.540653    0.7527708   0.06545985  0.38173938 -0.59338933\n",
      "    -0.08885768 -0.7484174   0.06518805 -0.0794943  -1.0302216\n",
      "     1.2297944  -0.57280743 -0.02944666  0.466384    1.4877474\n",
      "    -0.5524576   0.10193166  0.28188813 -0.32891408 -0.5453817\n",
      "     0.11537105  0.9191765 ]\n",
      "   [-0.744256    0.84860975 -0.23840299  1.2831665   0.28271124\n",
      "     0.12217765 -0.30792543 -0.00382918  0.18326329 -0.60353404\n",
      "    -0.5759614   0.6777829  -0.7366532   0.8947562   0.934778\n",
      "    -1.0111717  -0.07831566 -0.64069563 -1.4537498  -1.3975041\n",
      "    -1.6250954   0.14136893  0.9330588   0.75660527 -0.4122067\n",
      "     0.61318785  0.7171801   0.60563076 -1.0854374  -0.9993576\n",
      "    -0.24736848  0.26093554]]\n",
      "\n",
      "  [[ 0.6974818  -0.11565554  0.20734245  1.5678617   0.04437435\n",
      "     0.0828703   0.93008214 -0.84388983 -0.45585522  0.14291641\n",
      "    -0.12997729  0.47879317 -1.6175753  -0.90342516 -0.9128754\n",
      "     0.5173915   0.40849894  0.40233392  0.9349899   0.17965652\n",
      "     0.01188828  0.30738705  0.05485716 -0.52111495 -0.42814595\n",
      "    -0.13851616  0.54429317 -0.18280208 -0.17628014 -0.19956589\n",
      "    -0.42937165 -0.32516336]\n",
      "   [ 1.1147761  -0.69799435 -0.4060661  -0.6462839  -1.7214583\n",
      "     1.2981695   1.1262141  -0.5014486  -0.03010166  0.14480901\n",
      "     0.31602222  1.0550282   0.19897413 -0.1292022  -0.17031573\n",
      "    -0.47467214 -1.5283225   0.08160953 -0.02406961  0.4645767\n",
      "     0.81745976  0.26931497  0.01009809  1.7882137   2.4300861\n",
      "     0.09791481 -0.7835407  -0.47484186 -0.49152943  1.4591628\n",
      "    -0.20447049  0.5821501 ]\n",
      "   [ 0.7401365  -0.20663963  0.13450225  1.2515928  -0.20599666\n",
      "     0.2700898   0.92803    -0.797551   -0.38437387  0.10759279\n",
      "    -0.06819138  0.5585257  -1.3730757  -0.7841821  -0.83485967\n",
      "     0.356691    0.12375742  0.37113643  0.8036657   0.23583455\n",
      "     0.09935398  0.30658564  0.03700852 -0.17594981 -0.04875094\n",
      "    -0.12952541  0.34211555 -0.21462893 -0.21660672  0.03901631\n",
      "    -0.38890198 -0.17112929]\n",
      "   [ 0.5450478  -0.39768568  0.27195522  0.9621095  -0.40946183\n",
      "     0.6296498   0.5108689  -0.79070795 -0.17162278 -0.41634968\n",
      "    -0.03816697  0.5959129  -1.3561347  -0.5555263  -1.150889\n",
      "    -0.05273697 -0.24854371  0.54443574  0.76174676  0.5010582\n",
      "    -0.20182022  0.3698938  -0.13754411  0.3513022  -0.10030335\n",
      "    -0.4635631  -0.01571664 -0.10718879 -0.18855247  0.28016835\n",
      "    -0.23660493  0.3073225 ]]]], shape=(1, 4, 4, 32), dtype=float32)\n",
      "(1, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.random.randn(1,4,128)) # (문장수, 단어수, dmodel)\n",
    "\n",
    "mask = create_padding_mask(tf.constant([[1, 23, 777, 0]]))  # (1,1,1,4)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':mask })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]\n",
      " [ 7.  8.]\n",
      " [ 9. 10.]]\n",
      "tf.Tensor(\n",
      "[[ 0.    2.5 ]\n",
      " [ 3.75  5.  ]\n",
      " [ 6.25  0.  ]\n",
      " [ 8.75 10.  ]\n",
      " [11.25 12.5 ]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Dropout: 보통 10~50%\n",
    "# tf.random.set_seed(0) # set_seed()안하면 랜덤하게 지운다.\n",
    "layer = tf.keras.layers.Dropout(.2, input_shape=(2,)) # 0.2(20%)만큼 지운다\n",
    "data = np.arange(1,11).reshape(5, 2).astype(np.float32)\n",
    "print(data)\n",
    "\n",
    "outputs = layer(data, training=True) # 트레이닝 시\n",
    "print(outputs) # 5개 중 하나를 지운다.\n",
    "# outputs = layer(data, training=False) # 추론 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  0.  10.  20.  30.]\n",
      " [ 40.  50.  60.  70.]\n",
      " [ 80.  90. 100. 110.]\n",
      " [120. 130. 140. 150.]\n",
      " [160. 170. 180. 190.]\n",
      " [200. 210. 220. 230.]\n",
      " [240. 250. 260. 270.]\n",
      " [280. 290. 300. 310.]], shape=(8, 4), dtype=float32)\n",
      "[ 15.  55.  95. 135. 175. 215. 255. 295.] [11.18034 11.18034 11.18034 11.18034 11.18034 11.18034 11.18034 11.18034]\n",
      "<tf.Variable 'layer_normalization_7/beta:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>\n",
      "<tf.Variable 'layer_normalization_7/gamma:0' shape=(4,) dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]\n",
      " [-1.3416353 -0.4472118  0.4472118  1.3416353]], shape=(8, 4), dtype=float32)\n",
      "[-0.00000003 -0.00000003 -0.00000003 -0.00000003 -0.00000003 -0.00000003\n",
      " -0.00000003 -0.00000003] [0.99999595 0.99999595 0.99999595 0.99999595 0.99999595 0.99999595\n",
      " 0.99999595 0.99999595]\n"
     ]
    }
   ],
   "source": [
    "# Layer Normalization\n",
    "data = tf.constant(np.arange(32).reshape(8, 4) * 10, dtype=tf.float32)\n",
    "print(data)\n",
    "\n",
    "# 평균\n",
    "m = np.mean(data.numpy(), axis=1)\n",
    "# 표준편차\n",
    "s = np.std(data.numpy(), axis=1)\n",
    "print(m,s) # 45.0, 28.722813\n",
    "\n",
    "layer = tf.keras.layers.LayerNormalization(axis=1)\n",
    "output = layer(data)\n",
    "print(layer.beta) # default 평균 0\n",
    "print(layer.gamma) # default 표준편차 1\n",
    "print(output) # 값이 일정해짐 값 - 평균 / 표준편차 ex) 40 - 55 / 11.18034 = -1.3416\n",
    "\n",
    "m = np.mean(output.numpy(), axis=1)\n",
    "s = np.std(output.numpy(), axis=1)\n",
    "print(m,s) # 평균 0, 표준편차 1에 수렴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744.2\n",
      "697530.5599999999\n",
      "[ 0.43918521  1.76703799 -0.53185952 -0.84316855 -0.83119513]\n",
      "0.0\n",
      "0.9999999999999283\n",
      "0.0\n",
      "0.9999999999999283\n"
     ]
    }
   ],
   "source": [
    "# Normalization Scaling - beta, gamma\n",
    "\n",
    "x_i = np.array([1,2,3,4,5])\n",
    "x_i = np.array([1111,2220,300,40,50])\n",
    "k = len(x_i)\n",
    "mean_i = sum(x_i[j] for j in range(k)) / k\n",
    "print(mean_i) # 3.0\n",
    "var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k # 분산 = 증폭된 합 / k\n",
    "print(var_i) # 2.0\n",
    "\n",
    "# Normalization\n",
    "x_i_normalized = (x_i - mean_i) / np.sqrt(var_i + 0.0000001)\n",
    "print(x_i_normalized)\n",
    "print(np.mean(x_i_normalized)) # 평균 4.4408920985006264e-17 = 0에 수렴\n",
    "print(np.std(x_i_normalized)) # 표준편차 0.999999975000001 = 1에 수렴\n",
    "\n",
    "# default\n",
    "# gamma = 1\n",
    "# beta = 0\n",
    "\n",
    "# 학습을 통해 최적의 gamma, beta로 조정\n",
    "gamma = 2\n",
    "beta = 3\n",
    "\n",
    "output_i = x_i_normalized * gamma + beta\n",
    "print(np.mean(x_i_normalized)) \n",
    "print(np.std(x_i_normalized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff: affine(feedforward netwowrk) 은닉층의 뉴런수\n",
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")   # (None,None,128)\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")  # (None,1,1,None)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })       \n",
    "    \n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "\n",
    "    # 드롭아웃(Dropout) + 잔차 연결(Residual Connection)과 층 정규화(Layer Normalization)\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)  # 잔차 연결: (64,40,128) + (64,40,128)\n",
    "    \n",
    "#     print('attention.shape=', attention.shape)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)  # (N=64,T=40,H=128)(128,512)=>(64,40,512)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)  # (64,40,512)(512,128)=>(64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)  # 잔차 연결: (64,40,128) + (64,40,128)\n",
    "    \n",
    "    # 함수형 API: Model 내 Layers\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder: Embedding + Positional Encoding + encoder_layer를 여러층 쌓은 구조\n",
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "#     print(\"inputs.shape=\",inputs.shape)  # (None,None)\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\") # (None,1,1,None)\n",
    "#     print(\"padding_mask.shape=\",padding_mask.shape)\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃                                          # Input data: (N,T)\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # (9000,128) => (N,T,D)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))              # (64,40,128)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)      # (64,40,128)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40)\n",
      "(64, 1, 1, 40)\n",
      "(64, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 테스트\n",
    "\n",
    "# 인코더의 입력\n",
    "x = tf.constant(np.arange(64*40).reshape(64,40))  # (N,T)\n",
    "print(x.shape)\n",
    "\n",
    "# 인코더의 패딩 마스크 - Lambda가 create_padding_mask() 호출\n",
    "enc_padding_mask = tf.keras.layers.Lambda(\n",
    "    create_padding_mask, output_shape=(1, 1, 40),\n",
    "    name='enc_padding_mask')(x)\n",
    "\n",
    "print(enc_padding_mask.shape) # (N, 1, 1, T)\n",
    "\n",
    "# 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "enc_outputs = encoder(vocab_size=9000, num_layers=2, dff=512,\n",
    "    d_model=128, num_heads=4, dropout=0.2,)(inputs=[x, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "print(enc_outputs.shape) # (N, T, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]], shape=(4, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [-1  0  1  2]\n",
      " [ 0 -1  0  1]\n",
      " [ 0  0 -1  0]], shape=(4, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  0  0]\n",
      " [-1  0  1  0]\n",
      " [-2 -1  0  1]\n",
      " [ 0 -2 -1  0]], shape=(4, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 1 2 3]\n",
      " [0 0 1 2]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]], shape=(4, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  0  0  0]\n",
      " [-1  0  0  0]\n",
      " [-2 -1  0  0]\n",
      " [-3 -2 -1  0]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.linalg.band_part()\n",
    "a = tf.constant([[ 0,  1,  2, 3],\n",
    "                 [-1,  0,  1, 2],\n",
    "                 [-2, -1,  0, 1],\n",
    "                 [-3, -2, -1, 0]])\n",
    "\n",
    "print(tf.linalg.band_part(a, 0, 0))  # 대각선 기준 아래 lower, 위 upper\n",
    "print(tf.linalg.band_part(a, 1, -1)) # lower 1(1줄만), upper -1(전체)\n",
    "print(tf.linalg.band_part(a, 2, 1))  # lower 2(2줄), upper 1(1줄)\n",
    "print(tf.linalg.band_part(a, 0, -1)) # upper 전체\n",
    "print(tf.linalg.band_part(a, -1, 0)) # lower 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1.]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "seq_len=5\n",
    "a = tf.ones((seq_len, seq_len))\n",
    "print(a)\n",
    "\n",
    "print(tf.linalg.band_part(a, -1, 0))\n",
    "print(1-tf.linalg.band_part(a, -1, 0)) # 0과 1 반전\n",
    "\n",
    "# 1로 된 자리가 마스킹되어 사라진다. (s466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look ahead mask\n",
    "def create_look_ahead_mask(x):\n",
    "#     print(tf.shape(x)) # (1,5)\n",
    "    seq_len = tf.shape(x)[1] # (1,5)의 열의 크기(단어수) T = 5\n",
    "#     print(seq_len)  # 5\n",
    "    \n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) # (5, 5)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "#     return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 5], shape=(2,), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n",
      "tf.Tensor([1 5], shape=(2,), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[5, 4, 1, 6, 7]])))  # 단어 길이 5인 문장 (N,T) => (1,5)\n",
    "print(create_look_ahead_mask(tf.constant([[5, 4, 1, 0, 0]])))  # 단어 길이 3인 문장, 패딩 마스크 있는 경우(N,T) => (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    # inputs: 인코더의 input, dec_inputs: 디코더의 input, outputs: 디코더의 output\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"look_ahead_mask/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"look_ahead_mask/strided_slice:0\", shape=(), dtype=int32)\n",
      "(9000, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "(9000, 64)\n",
      "tf.Tensor(\n",
      "[[ 1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.        ]\n",
      " [ 0.5403023   0.6479058   0.731761    0.7964579   0.84600914  0.8837559\n",
      "   0.91239583  0.9340616   0.95041525  0.962739  ]\n",
      " [-0.4161468  -0.16043602  0.07094827  0.2686903   0.43146282  0.56204915\n",
      "   0.66493237  0.74494207  0.8065784   0.8537328 ]\n",
      " [-0.9899925  -0.8558007  -0.6279267  -0.36845687 -0.11596616  0.1096727\n",
      "   0.3009673   0.45758203  0.58275366  0.6811047 ]\n",
      " [-0.6536436  -0.94852054 -0.9899327  -0.855611   -0.6276797  -0.36820143\n",
      "  -0.11572982  0.10987744  0.30113748  0.45771942]\n",
      " [ 0.28366217 -0.3733035  -0.82086164 -0.99445945 -0.94607925 -0.760473\n",
      "  -0.5121501  -0.2523174  -0.01034234  0.2002239 ]\n",
      " [ 0.96017027  0.46478963 -0.21141617 -0.728479   -0.9731037  -0.9759438\n",
      "  -0.81883734 -0.5812374  -0.32079637 -0.07219268]\n",
      " [ 0.75390226  0.9755833   0.5114493  -0.16594627 -0.7004298  -0.9645192\n",
      "  -0.98205763 -0.83350575 -0.5994375  -0.33922932]\n",
      " [-0.14550003  0.79938257  0.95993346  0.4641406  -0.21203645 -0.72885543\n",
      "  -0.9732132  -0.9758539  -0.8186324  -0.5809859 ]\n",
      " [-0.91113025  0.06026585  0.89343446  0.90528315  0.34166023 -0.32374159\n",
      "  -0.7938539  -0.9895096  -0.9566442  -0.7794462 ]], shape=(10, 10), dtype=float32)\n",
      "(9000, 64)\n",
      "(9000, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_0/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_0/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder_layer_0/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_0/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_1/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_1/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder_layer_1/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_1/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_2/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_2/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder_layer_2/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_2/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_3/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_3/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder_layer_3/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_3/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder/encoder_layer_0/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_0/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_0/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_0/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder/encoder_layer_1/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_1/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_1/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_1/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder/encoder_layer_2/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_2/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_2/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_2/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= Tensor(\"encoder/encoder_layer_3/attention/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_3/attention/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_3/attention/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_3/attention/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "(9000, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "(9000, 64)\n",
      "tf.Tensor(\n",
      "[[ 1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.          1.        ]\n",
      " [ 0.5403023   0.6479058   0.731761    0.7964579   0.84600914  0.8837559\n",
      "   0.91239583  0.9340616   0.95041525  0.962739  ]\n",
      " [-0.4161468  -0.16043602  0.07094827  0.2686903   0.43146282  0.56204915\n",
      "   0.66493237  0.74494207  0.8065784   0.8537328 ]\n",
      " [-0.9899925  -0.8558007  -0.6279267  -0.36845687 -0.11596616  0.1096727\n",
      "   0.3009673   0.45758203  0.58275366  0.6811047 ]\n",
      " [-0.6536436  -0.94852054 -0.9899327  -0.855611   -0.6276797  -0.36820143\n",
      "  -0.11572982  0.10987744  0.30113748  0.45771942]\n",
      " [ 0.28366217 -0.3733035  -0.82086164 -0.99445945 -0.94607925 -0.760473\n",
      "  -0.5121501  -0.2523174  -0.01034234  0.2002239 ]\n",
      " [ 0.96017027  0.46478963 -0.21141617 -0.728479   -0.9731037  -0.9759438\n",
      "  -0.81883734 -0.5812374  -0.32079637 -0.07219268]\n",
      " [ 0.75390226  0.9755833   0.5114493  -0.16594627 -0.7004298  -0.9645192\n",
      "  -0.98205763 -0.83350575 -0.5994375  -0.33922932]\n",
      " [-0.14550003  0.79938257  0.95993346  0.4641406  -0.21203645 -0.72885543\n",
      "  -0.9732132  -0.9758539  -0.8186324  -0.5809859 ]\n",
      " [-0.91113025  0.06026585  0.89343446  0.90528315  0.34166023 -0.32374159\n",
      "  -0.7938539  -0.9895096  -0.9566442  -0.7794462 ]], shape=(10, 10), dtype=float32)\n",
      "(9000, 64)\n",
      "(9000, 128)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_0/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_0/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_0/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_0/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_1/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_1/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_1/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_1/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= Tensor(\"decoder_layer_2/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_2/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_2/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_2/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_2/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_2/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_2/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_2/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_3/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_3/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_3/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_3/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_3/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_3/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder_layer_3/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_3/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_0/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_0/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_0/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_0/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_1/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_1/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_1/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_1/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_2/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_2/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_2/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_2/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_2/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_2/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_2/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_2/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_3/attention_1/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_3/attention_1/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_3/attention_1/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_3/attention_1/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_3/attention_2/add:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_3/attention_2/Softmax:0\", shape=(None, 4, None, None), dtype=float32)\n",
      "value.shape= (None, 4, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_3/attention_2/transpose_2:0\", shape=(None, 4, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_3/attention_2/MatMul_1:0\", shape=(None, 4, None, 32), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder의 loss_function() - 다중 분류\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy( \n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32) # y_true(one-hot encoding): 값이 0인 경우는 제외되고, 1인 경우만 loss\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Customized Learning Rate Setting\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps # make learning rate faster or slower\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "# learning rate가 급격히 증가하다가, 지수적으로 감소시키는 것이 좋다.\n",
    "# learning rate를 가변적으로 적용할 수 있다.\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 25.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.19.4)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.8/95.8 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: toml in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: promise in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.26.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
      "     ---------------------------------------- 51.0/51.0 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.1/98.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.21.3)\n",
      "Requirement already satisfied: six in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Collecting importlib_resources\n",
      "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: zipp in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow_datasets) (3.6.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "     ------------------------------------- 211.7/211.7 kB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.4)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\chaek\\anaconda3\\lib\\site-packages (from etils[epath]->tensorflow_datasets) (3.10.0.2)\n",
      "Installing collected packages: importlib_resources, googleapis-common-protos, etils, dill, tensorflow-metadata, tensorflow_datasets\n",
      "Successfully installed dill-0.3.5.1 etils-0.6.0 googleapis-common-protos-1.56.4 importlib_resources-5.9.0 tensorflow-metadata-1.9.0 tensorflow_datasets-4.6.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅 데이터(약 1만개)\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('./ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12시 땡 !]\n"
     ]
    }
   ],
   "source": [
    "# 전처리 - 정규표현식\n",
    "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", \"   12시 땡!    \") # 구두점 다음 공백 추가 (단어로 분리)\n",
    "sentence = sentence.strip() # 공백 제거\n",
    "print(\"[%s]\"%sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n",
      "11823\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8178\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing: 서브워드 텍스트 인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "print(tokenizer.vocab_size) # unique 단어 개수: 8178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰<sos>과 종료 토큰<eos>에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1] # <sos>:8178, <eos>:8179로 추가\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가스비 비싼데 감기 걸리겠어\n",
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print(questions[20])\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n",
    "# 어절 단위가 아니라 형태소 단위로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "# Tokenized 형태소 확인 (7개의 형태소)\n",
    "# tensorflow 자체에서 지원하는 형태소분석기 사용\n",
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가스비 비싼데 감기 걸리겠어\n",
      "[5766, 611, 3509, 141, 685, 3747, 849]\n",
      "[8178, 5766, 611, 3509, 141, 685, 3747, 849, 8179]\n",
      "[[8178, 5766, 611, 3509, 141, 685, 3747, 849, 8179]]\n",
      "(1, 40)\n"
     ]
    }
   ],
   "source": [
    "# 패딩\n",
    "MAX_LENGTH = 40\n",
    "sentence1 = questions[20]\n",
    "print(sentence1)\n",
    "print(tokenizer.encode(sentence1))\n",
    "sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "print(sentence1) # 양쪽 끝에 <sos> 8178, <eos> 8179 추가됨\n",
    "\n",
    "tokenized_inputs=[]\n",
    "tokenized_inputs.append(sentence1)\n",
    "print(tokenized_inputs)\n",
    "tokenized_inputs=tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "print(tokenized_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        #     print(sentence1)\n",
    "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1) # question\n",
    "    tokenized_outputs.append(sentence2) # answer\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    print(tokenized_inputs[0])\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got array([8178, 7915, 4207, 3060,   41, 8179,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21196/105413635.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize_and_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21196/2726756049.py\u001b[0m in \u001b[0;36mtokenize_and_filter\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#     print(sentence1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msentence1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0msentence2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTART_TOKEN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mEND_TOKEN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\deprecated\\text\\subword_text_encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;34m\"\"\"Encodes text into a list of integers.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_tokens_for_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_text\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got array([8178, 7915, 4207, 3060,   41, 8179,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0])"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "# <SOS> -> you, you->say, say->goodbye, ...\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # (정답) 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) # 1번째 batch fetch 시 2번째 batch가 자동으로 메모리로 올라온다.\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 입력: 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 출력: 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"look_ahead_mask/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"look_ahead_mask/strided_slice:0\", shape=(), dtype=int32)\n",
      "(8180, 256)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.8019618   0.7617204   0.72141415  0.68156135  0.6425569\n",
      "   0.604694    0.5681832   0.53316844  0.4997405 ]\n",
      " [ 0.9092974   0.95814437  0.98704624  0.9991642   0.99748     0.984703\n",
      "   0.9632266   0.9351183   0.9021307   0.86572564]\n",
      " [ 0.14112     0.34278184  0.51730573  0.662436    0.7782725   0.86647683\n",
      "   0.9296448   0.97083837  0.9932532   0.9999996 ]\n",
      " [-0.7568025  -0.5486055  -0.31671554 -0.08168512  0.14153895  0.3431518\n",
      "   0.5176193   0.6626916   0.7784717   0.866624  ]\n",
      " [-0.9589243  -0.99822867 -0.9277093  -0.7755705  -0.5711271  -0.34060496\n",
      "  -0.10512096  0.11982207  0.32393527  0.5012968 ]\n",
      " [-0.2794155  -0.64402884 -0.88542116 -0.9924861  -0.97739613 -0.8651204\n",
      "  -0.6850681  -0.4654877  -0.23036753  0.00179783]\n",
      " [ 0.6569866   0.22877482 -0.2196297  -0.5990306  -0.8593135  -0.9851716\n",
      "  -0.98613477 -0.8859239  -0.7137213  -0.49818248]\n",
      " [ 0.98935825  0.9173577   0.6008224   0.16282429 -0.28022808 -0.64463127\n",
      "  -0.88576156 -0.9925694  -0.9772618  -0.8648244 ]\n",
      " [ 0.41211846  0.86723864  0.99818236  0.8245435   0.4491935  -0.00271016\n",
      "  -0.4248087  -0.7476511  -0.9398235  -0.99999636]], shape=(10, 10), dtype=float32)\n",
      "(8180, 128)\n",
      "tf.Tensor(\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 5.40302277e-01  5.97375333e-01  6.47905827e-01  6.92503870e-01\n",
      "   7.31760979e-01  7.66237974e-01  7.96457887e-01  8.22902083e-01\n",
      "   8.46009135e-01  8.66175175e-01]\n",
      " [-4.16146815e-01 -2.86285400e-01 -1.60436019e-01 -4.08767238e-02\n",
      "   7.09482655e-02  1.74241275e-01  2.68690288e-01  3.54335696e-01\n",
      "   4.31462824e-01  5.00518858e-01]\n",
      " [-9.89992499e-01 -9.39415038e-01 -8.55800688e-01 -7.49118507e-01\n",
      "  -6.27926707e-01 -4.99217302e-01 -3.68456870e-01 -2.39734888e-01\n",
      "  -1.15966164e-01  8.98913422e-04]\n",
      " [-6.53643608e-01 -8.36081326e-01 -9.48520541e-01 -9.96658206e-01\n",
      "  -9.89932716e-01 -9.39279974e-01 -8.55611026e-01 -7.48892426e-01\n",
      "  -6.27679706e-01 -4.98961747e-01]\n",
      " [ 2.83662170e-01 -5.94936647e-02 -3.73303503e-01 -6.31260931e-01\n",
      "  -8.20861638e-01 -9.40206528e-01 -9.94459450e-01 -9.92795408e-01\n",
      "  -9.46079254e-01 -8.65275383e-01]\n",
      " [ 9.60170269e-01  7.65001178e-01  4.64789629e-01  1.22357085e-01\n",
      "  -2.11416170e-01 -5.01564205e-01 -7.28479028e-01 -8.85054350e-01\n",
      "  -9.73103702e-01 -9.99998391e-01]\n",
      " [ 7.53902256e-01  9.73479390e-01  9.75583315e-01  8.00726116e-01\n",
      "   5.11449277e-01  1.71571702e-01 -1.65946275e-01 -4.63830531e-01\n",
      "  -7.00429797e-01 -8.67072225e-01]\n",
      " [-1.45500034e-01  3.98063928e-01  7.99382567e-01  9.86655056e-01\n",
      "   9.59933460e-01  7.64493644e-01  4.64140594e-01  1.21679828e-01\n",
      "  -2.12036446e-01 -5.02074361e-01]\n",
      " [-9.11130250e-01 -4.97892678e-01  6.02658540e-02  5.65798581e-01\n",
      "   8.93434465e-01  9.99996305e-01  9.05283153e-01  6.64091706e-01\n",
      "   3.41660231e-01 -2.69649900e-03]], shape=(10, 10), dtype=float32)\n",
      "(8180, 128)\n",
      "(8180, 256)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.8019618   0.7617204   0.72141415  0.68156135  0.6425569\n",
      "   0.604694    0.5681832   0.53316844  0.4997405 ]\n",
      " [ 0.9092974   0.95814437  0.98704624  0.9991642   0.99748     0.984703\n",
      "   0.9632266   0.9351183   0.9021307   0.86572564]\n",
      " [ 0.14112     0.34278184  0.51730573  0.662436    0.7782725   0.86647683\n",
      "   0.9296448   0.97083837  0.9932532   0.9999996 ]\n",
      " [-0.7568025  -0.5486055  -0.31671554 -0.08168512  0.14153895  0.3431518\n",
      "   0.5176193   0.6626916   0.7784717   0.866624  ]\n",
      " [-0.9589243  -0.99822867 -0.9277093  -0.7755705  -0.5711271  -0.34060496\n",
      "  -0.10512096  0.11982207  0.32393527  0.5012968 ]\n",
      " [-0.2794155  -0.64402884 -0.88542116 -0.9924861  -0.97739613 -0.8651204\n",
      "  -0.6850681  -0.4654877  -0.23036753  0.00179783]\n",
      " [ 0.6569866   0.22877482 -0.2196297  -0.5990306  -0.8593135  -0.9851716\n",
      "  -0.98613477 -0.8859239  -0.7137213  -0.49818248]\n",
      " [ 0.98935825  0.9173577   0.6008224   0.16282429 -0.28022808 -0.64463127\n",
      "  -0.88576156 -0.9925694  -0.9772618  -0.8648244 ]\n",
      " [ 0.41211846  0.86723864  0.99818236  0.8245435   0.4491935  -0.00271016\n",
      "  -0.4248087  -0.7476511  -0.9398235  -0.99999636]], shape=(10, 10), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_0/attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_0/attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"encoder_layer_0/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_0/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder_layer_1/attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder_layer_1/attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"encoder_layer_1/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder_layer_1/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder/encoder_layer_0/attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_0/attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_0/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_0/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"encoder/encoder_layer_1/attention/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"encoder/encoder_layer_1/attention/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"encoder/encoder_layer_1/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"encoder/encoder_layer_1/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "(8180, 256)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.8019618   0.7617204   0.72141415  0.68156135  0.6425569\n",
      "   0.604694    0.5681832   0.53316844  0.4997405 ]\n",
      " [ 0.9092974   0.95814437  0.98704624  0.9991642   0.99748     0.984703\n",
      "   0.9632266   0.9351183   0.9021307   0.86572564]\n",
      " [ 0.14112     0.34278184  0.51730573  0.662436    0.7782725   0.86647683\n",
      "   0.9296448   0.97083837  0.9932532   0.9999996 ]\n",
      " [-0.7568025  -0.5486055  -0.31671554 -0.08168512  0.14153895  0.3431518\n",
      "   0.5176193   0.6626916   0.7784717   0.866624  ]\n",
      " [-0.9589243  -0.99822867 -0.9277093  -0.7755705  -0.5711271  -0.34060496\n",
      "  -0.10512096  0.11982207  0.32393527  0.5012968 ]\n",
      " [-0.2794155  -0.64402884 -0.88542116 -0.9924861  -0.97739613 -0.8651204\n",
      "  -0.6850681  -0.4654877  -0.23036753  0.00179783]\n",
      " [ 0.6569866   0.22877482 -0.2196297  -0.5990306  -0.8593135  -0.9851716\n",
      "  -0.98613477 -0.8859239  -0.7137213  -0.49818248]\n",
      " [ 0.98935825  0.9173577   0.6008224   0.16282429 -0.28022808 -0.64463127\n",
      "  -0.88576156 -0.9925694  -0.9772618  -0.8648244 ]\n",
      " [ 0.41211846  0.86723864  0.99818236  0.8245435   0.4491935  -0.00271016\n",
      "  -0.4248087  -0.7476511  -0.9398235  -0.99999636]], shape=(10, 10), dtype=float32)\n",
      "(8180, 128)\n",
      "tf.Tensor(\n",
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 5.40302277e-01  5.97375333e-01  6.47905827e-01  6.92503870e-01\n",
      "   7.31760979e-01  7.66237974e-01  7.96457887e-01  8.22902083e-01\n",
      "   8.46009135e-01  8.66175175e-01]\n",
      " [-4.16146815e-01 -2.86285400e-01 -1.60436019e-01 -4.08767238e-02\n",
      "   7.09482655e-02  1.74241275e-01  2.68690288e-01  3.54335696e-01\n",
      "   4.31462824e-01  5.00518858e-01]\n",
      " [-9.89992499e-01 -9.39415038e-01 -8.55800688e-01 -7.49118507e-01\n",
      "  -6.27926707e-01 -4.99217302e-01 -3.68456870e-01 -2.39734888e-01\n",
      "  -1.15966164e-01  8.98913422e-04]\n",
      " [-6.53643608e-01 -8.36081326e-01 -9.48520541e-01 -9.96658206e-01\n",
      "  -9.89932716e-01 -9.39279974e-01 -8.55611026e-01 -7.48892426e-01\n",
      "  -6.27679706e-01 -4.98961747e-01]\n",
      " [ 2.83662170e-01 -5.94936647e-02 -3.73303503e-01 -6.31260931e-01\n",
      "  -8.20861638e-01 -9.40206528e-01 -9.94459450e-01 -9.92795408e-01\n",
      "  -9.46079254e-01 -8.65275383e-01]\n",
      " [ 9.60170269e-01  7.65001178e-01  4.64789629e-01  1.22357085e-01\n",
      "  -2.11416170e-01 -5.01564205e-01 -7.28479028e-01 -8.85054350e-01\n",
      "  -9.73103702e-01 -9.99998391e-01]\n",
      " [ 7.53902256e-01  9.73479390e-01  9.75583315e-01  8.00726116e-01\n",
      "   5.11449277e-01  1.71571702e-01 -1.65946275e-01 -4.63830531e-01\n",
      "  -7.00429797e-01 -8.67072225e-01]\n",
      " [-1.45500034e-01  3.98063928e-01  7.99382567e-01  9.86655056e-01\n",
      "   9.59933460e-01  7.64493644e-01  4.64140594e-01  1.21679828e-01\n",
      "  -2.12036446e-01 -5.02074361e-01]\n",
      " [-9.11130250e-01 -4.97892678e-01  6.02658540e-02  5.65798581e-01\n",
      "   8.93434465e-01  9.99996305e-01  9.05283153e-01  6.64091706e-01\n",
      "   3.41660231e-01 -2.69649900e-03]], shape=(10, 10), dtype=float32)\n",
      "(8180, 128)\n",
      "(8180, 256)\n",
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.8019618   0.7617204   0.72141415  0.68156135  0.6425569\n",
      "   0.604694    0.5681832   0.53316844  0.4997405 ]\n",
      " [ 0.9092974   0.95814437  0.98704624  0.9991642   0.99748     0.984703\n",
      "   0.9632266   0.9351183   0.9021307   0.86572564]\n",
      " [ 0.14112     0.34278184  0.51730573  0.662436    0.7782725   0.86647683\n",
      "   0.9296448   0.97083837  0.9932532   0.9999996 ]\n",
      " [-0.7568025  -0.5486055  -0.31671554 -0.08168512  0.14153895  0.3431518\n",
      "   0.5176193   0.6626916   0.7784717   0.866624  ]\n",
      " [-0.9589243  -0.99822867 -0.9277093  -0.7755705  -0.5711271  -0.34060496\n",
      "  -0.10512096  0.11982207  0.32393527  0.5012968 ]\n",
      " [-0.2794155  -0.64402884 -0.88542116 -0.9924861  -0.97739613 -0.8651204\n",
      "  -0.6850681  -0.4654877  -0.23036753  0.00179783]\n",
      " [ 0.6569866   0.22877482 -0.2196297  -0.5990306  -0.8593135  -0.9851716\n",
      "  -0.98613477 -0.8859239  -0.7137213  -0.49818248]\n",
      " [ 0.98935825  0.9173577   0.6008224   0.16282429 -0.28022808 -0.64463127\n",
      "  -0.88576156 -0.9925694  -0.9772618  -0.8648244 ]\n",
      " [ 0.41211846  0.86723864  0.99818236  0.8245435   0.4491935  -0.00271016\n",
      "  -0.4248087  -0.7476511  -0.9398235  -0.99999636]], shape=(10, 10), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_0/attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_0/attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_0/attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_0/attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "[]\n",
      "logits= Tensor(\"attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_1/attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_1/attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder_layer_1/attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder_layer_1/attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_0/attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_0/attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_0/attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_0/attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_1/attention_1/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_1/attention_1/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"decoder/decoder_layer_1/attention_2/add:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "attention_weights= Tensor(\"decoder/decoder_layer_1/attention_2/Softmax:0\", shape=(None, 8, None, None), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"decoder/decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"decoder/decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 스케쥴러 사용\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "logits= Tensor(\"transformer/encoder/encoder_layer_0/attention/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/encoder/encoder_layer_0/attention/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/encoder/encoder_layer_0/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/encoder/encoder_layer_0/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/encoder/encoder_layer_1/attention/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/encoder/encoder_layer_1/attention/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/encoder/encoder_layer_1/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/encoder/encoder_layer_1/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "Tensor(\"transformer/look_ahead_mask/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"transformer/look_ahead_mask/strided_slice:0\", shape=(), dtype=int32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/add:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/Softmax:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 8, 39, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/add:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/Softmax:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 8, 39, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/encoder/encoder_layer_0/attention/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/encoder/encoder_layer_0/attention/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/encoder/encoder_layer_0/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/encoder/encoder_layer_0/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/encoder/encoder_layer_1/attention/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/encoder/encoder_layer_1/attention/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/encoder/encoder_layer_1/attention/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/encoder/encoder_layer_1/attention/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "Tensor(\"transformer/look_ahead_mask/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"transformer/look_ahead_mask/strided_slice:0\", shape=(), dtype=int32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/add:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/Softmax:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_0/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_0/attention_1/MatMul_1:0\", shape=(None, 8, 39, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_0/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_0/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/add:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/Softmax:0\", shape=(None, 8, 39, 39), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_1/attention_1/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_1/attention_1/MatMul_1:0\", shape=(None, 8, 39, 32), dtype=float32)\n",
      "logits= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/add:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "attention_weights= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/Softmax:0\", shape=(None, 8, None, 40), dtype=float32)\n",
      "value.shape= (None, 8, None, 32)\n",
      "value= Tensor(\"transformer/decoder/decoder_layer_1/attention_2/transpose_2:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "output = Tensor(\"transformer/decoder/decoder_layer_1/attention_2/MatMul_1:0\", shape=(None, 8, None, 32), dtype=float32)\n",
      "185/185 [==============================] - 151s 779ms/step - loss: 1.4485 - accuracy: 0.0213\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 145s 786ms/step - loss: 1.1779 - accuracy: 0.0473\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 141s 765ms/step - loss: 1.0046 - accuracy: 0.0505\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 143s 771ms/step - loss: 0.9299 - accuracy: 0.0545\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 141s 764ms/step - loss: 0.8737 - accuracy: 0.0574\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 143s 775ms/step - loss: 0.8140 - accuracy: 0.0614\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 142s 766ms/step - loss: 0.7481 - accuracy: 0.0676\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 142s 765ms/step - loss: 0.6740 - accuracy: 0.0754\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 142s 768ms/step - loss: 0.5953 - accuracy: 0.0838\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 142s 767ms/step - loss: 0.5118 - accuracy: 0.0932\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 143s 771ms/step - loss: 0.4287 - accuracy: 0.1036\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 144s 777ms/step - loss: 0.3473 - accuracy: 0.1142\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 145s 784ms/step - loss: 0.2714 - accuracy: 0.1256\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 145s 783ms/step - loss: 0.2052 - accuracy: 0.1360\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 146s 789ms/step - loss: 0.1510 - accuracy: 0.1454\n",
      "Epoch 16/50\n",
      " 45/185 [======>.......................] - ETA: 1:51 - loss: 0.0936 - accuracy: 0.1575"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    print(sentence)\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    print(sentence)\n",
    "    \n",
    "    print(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN)\n",
    "    # 0축 추가\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "#     print(sentence)\n",
    "\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "    print(output)\n",
    "    \n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "        break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "    \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "Input: 날씨가 좋넹.\n",
      "Output: 천천히 생각이 많아지기 때문일 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"   날씨가 좋넹.   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(15, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(17, shape=(), dtype=int32)\n",
      "Input: 고민이 있어\n",
      "Output: 생각을 종이에 끄젹여여 보는게 도움이 될 수도 있어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "Input: 카페갈래?\n",
      "Output: 카페 데이트 좋죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "Input: 게임하고싶당\n",
      "Output: 무슨 마음인지 알겠어서 더 마음이 아프네요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "Input: 게임하자\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
